## [原文转写文稿](https://www.youtube.com/watch?v=oPl15CRBfvQ&t=2724s)
Welcome to the stage, Nvidia founder and CEO, Jensen Wong.
Hello, Las Vegas. Happy New Year.
Welcome to CES. Well, we have about 15 kilos worth of
material to pack in here. I'm so happy to see all of you. You got 3,000 people in this auditorium. There's 2,000 people
in a courtyard watching us. There's another thousand people apparently in the fourth floor where there were
supposed to be Nvidia show floors all watching this keynote and of course millions around the world are going to
be watching this to kick off this new year. Well, every 10 to 15 years the
computer industry resets. A new platform shift happens
from mainframe to PC, PC to internet, internet to cloud, cloud to mobile. Each
time the world of applications target a new platform, that's why it's
called a platform shift. You write new applications for a new computer.
Except this time there are two simultaneous platform shifts in fact happening at the same
time. While we now move to AI, applications
are now going to be built on top of AI. At first people thought AIs are applications and in fact AIs are
applications but you're going to build applications on top of AIS
but in addition to that how you run the software how you develop
the software fundamentally changed. The entire fabulary stack of the computer industry
is being reinvented. You no longer program the software, you
train the software. You don't run it on CPUs, you run it on GPUs.
And whereas applications were pre-recorded, pre-ompiled
and run on your device, now applications understand the context and generate
every single pixel, every single token completely from scratch every single time.
Computing has been fundamentally reshaped as a result of accelerated computing, as a result of artificial
intelligence. Every single layer of that five layer cake is now being re
reinvented. Well, what that means is some 10 trillion dollars or so of the last
decade of computing is now being modernized to this new way of doing computing. What that means is hundreds
of billions of dollars, a couple hundred billion dollars in VC funding each year is going into modernizing and inventing
this new world. And what it means is a hundred trillion dollars of industry,
several percent of which is R&D budget is shifting over to artificial intelligence. People ask where is the
money coming from? That's where the money is coming from. the modernization of AI to AI, the shifting of R&D budgets
from classical methods to now artificial intelligence methods, enormous amounts
of investments coming into this industry, which explains why we're so busy. And this last year was no
difference. This last year was incredible. This last year, there's a slide coming.
This is what happens when you don't practice. This is the first keynote of the year. I
hope it's your first keynote of the year. Otherwise, you can you have been pretty pretty busy. It's our first keynote of the year. We're going to get
the spiderwebs out. And so 2025 was an
incredible year. It's just see it seemed like everything was happening all at the same time. And
it in fact it probably was. The first thing of course is scaling loss.
In 2015, the first language model that I thought
was really going to make a difference made a huge difference. It was called BERT. 2017, Transformers came. It wasn't
until 5 years later, 2022, that chat GPT moment happened and it awakened the
world to the possibilities of artificial intelligence. Something very important happened a year
after that. The first 01 model from chat GPT the first reasoning model completely
revolutionary invented this idea called test time scaling which is very common sens common sensical thing not only do
we pre-train a model to learn we postrain it with our re reinforcement learning so that it could learn skills
and now we also have test time scaling which is another way of saying thinking you think in real time each one of these
phases of artificial intelligence requires enormous amount of comput and the computing law continued to scale.
Large language models continued to get better. Meanwhile, another breakthrough happened and this breakthrough happened
in 2024. Agentic systems started to emerge in 2025. It started to pervase to to uh
proliferate just about everywhere. Agentic models that have the ability to reason,
look up information, do research, use tools, plan futures, simulate outcomes.
All of a sudden started to solve very very important problems. One of my favorite Agentic models is called cursor
which revolutionized the way we do software programming at NVIDIA. Agentic systems are going to really take off
from here. Of course, there were other types of AI. We know that large language models isn't the only type of
information. Wherever the universe has information, wherever the universe has structure, we could teach a large
language model a form of language model to go understand that information to
understand its representation and to turn that into an AI. One of the biggest
most important one is physical AI. AIs that understand the laws of nature. And
then of course physical AI is about AIs interacting with the world but the world
itself has information encoded information and that's called AI physics. AI that in the case of physical
AI you have AI that interacts with the physical world and you have AI physics AI that understands the laws of physics.
And then lastly one of the most important things that happened last year the advancement of open models. We can
now know that AI is going to proliferate everywhere when open source when open
innovation when innovation across every single company and every industry around the world is activated. At the same
time, open models really took off last year. In fact,
last year we saw the advance of DeepSeek R1, the first open model that's a
reasoning system. It caught the world by surprise and it activated literally this
entire movement. Really, really exciting work. We're so happy with it. Now we
have openings open model systems all over the world of all different kinds and we now know that open models have
also reached the frontier. still solidly is six months behind the frontier models
but every single six months a new model is emerging and these models are getting
smarter and smarter because of that you could see the number of downloads has
exploded the number of downloads is growing so fast because startups want to
participate in the AI revolution large companies want to researchers want to students want to just about every single
country wants How is it possible that intelligence, the digital form of intelligence will
leave anyone behind and so open models has really revolutionized artificial
intelligence last year. This entire industry is going to be reshaped as a result of that. Now, we had this inkling
some time ago. You might have heard that several years ago, we started to build
and operate our own AI supercomputers. We call them DGX clouds. A lot of people
asked, are you going to in going into the cloud business? The answer is no. We're building these DGX supercomputers
for our own use. Well, it turns out we have billions of dollars of supercomputers in operation so that we
could develop our open models. I am so pleased with the work that we're doing.
It is starting to attract attention all over the world and all over the industries because we are doing frontier
AI model work in so many different domains. the work that we did in proteins in digital biology. La Protina
to be able to synthesize and generate proteins. Open F3 to understand the
understand the structure of proteins. EVO 2 how to understand and generate
multiple proteins otherwise the beginnings of cellular cellular representation. Earth 2 AI that
understands laws of physics. The work that we did with forecast net, the work that we did with Cordiff really
revolutionized the way that people are doing weather prediction. Neotron,
we've now doing groundbreaking work there. The first hybrid transformer SSM
model that's incredibly fast can and therefore can think for a very long time
or can think very quickly with that for not a very long time and produce very very smart intelligent answers.
Neimotron 3 is groundbreaking work and you can expect us to deliver other versions of Neimotron 3 in the near
future. Cosmos a frontier open world foundation model
one that understand how the world works. Groot a humanoid robotic system
articulation mobility locomotion. These models, these technologies are now being
integrated and in the each one of these cases open to the world. Frontier human
or robotics models open to the world. And then today we're going to talk a little bit about Alpamo, the work that
we've been doing in self-driving cars. Not only do we open source the models,
we also open source the data that we use to train those models because that in
that way only in that way can you truly trust how the models came to be. We open
source all the models. We help you make derivatives from them. We have a whole suite of libraries we call the Nemo
libraries, physics li physics nemo libraries and the clarono libraries. Each biono libraries each one of these
libraries are life cycle management systems of AIS so that you could process the data you could generate data you
could train the model you could create the model evaluate the model guardrail the model all the way to deploying the
model each one of these libraries are incredibly complex and all of it is open
sourced and so now on top of this platform NVIDIA is a frontier AI model
builder and we build it in a very special way. We build it completely in the open so that we can enable every
company, every industry, every country to be part of this AI revolution. I'm
incredibly proud of the work that we're doing there. In fact, if you notice the tren the charts, the chart shows that
our contribution to this industry is bar none and you're going to see us in fact continue to do that if not accelerate.
These models are also world class. All systems are down.
This never happens in Santa Clara. Is it because of Las Vegas?
Somebody must have went won a jackpot outside. All systems are down.
Okay, I think my system's still down, but that's okay. I I I've I uh I'll make
it up as I go. And so so uh not only are these models uh frontier capable, not
only are they open, they're also top the leaderboards. This is an area where we're very proud. They top leaderboards
in intelligence. Uh we have uh uh important models that understand multimodality documents, otherwise known
as PDFs. The most valuable content in the world are captured in PDFs. But
there it takes artificial intelligence to find out what's inside, interpret what's inside, and help you read it. And
so our PDF retrievers, our PDF parsers are worldclass.
Our speech recognition models absolutely worldclass. Our retrieval models, basically search, semantic search, AI
search, the database engine of the modern AI era, worldclass. So we're on
top of leaderboards constantly. This is an area we're very proud of and all of that is in service of your ability to
build AI agents. This is really a groundbreaking area of development. You
know at first when pe when chat GPT came out people said you know uh gosh it it
produced really interesting results but it hallucinated greatly. And the reason why it hallucinated, of course, it could
memorize everything um in the past, but it can't memorize everything in the future, in the current. And so it needs
to be grounded in research. It has to do fundamental research before it answers a
question. The ability to reason about do I have to do research? Do I have to use tools? How do I break up a problem into
steps? Each one of these steps something that that the AI model knows how to do.
And together it is able to compose it into a sequence of steps to perform something it's never done before, never
been trained to do. This is the wonderful capability of reasoning. We could we could be we can encounter a
circumstance we've never seen before and break it down into circumstances and
knowledge or rules that we know how to do because we've experienced it in the
past. And so the ability for AI models now to be able to reason incredibly powerful.
The reasoning capability of agents opened the doors to all of these different applications. We no longer
have to train an AI model to know everything on day one. Just as we don't
have to know everything on day one, that we should be able to in every circumstance reason about how to solve
that problem. Large language models has now made this fundamental leap. The
ability to use reinforcement learning and chain of thought and you know search and planning and all these different
techniques in reinforcement learning has made it possible for us to have this basic capability and is also now
completely open sourced. But the thing that's really terrific is another breakthrough that happened and the first
time I saw it was with Arvin's perplexity. Perplexity, the search
company, the AI search company, really f really innovative company. And the first time I realized they were using multiple
models at the same time, I thought it was completely genius. Of course, we would do that. Of course, an AI would
also call upon all of the world's great AIs to solve the problem it wants to solve at any part of the reasoning
chain. And this is the reason why AIs are really multi-modal
meaning they understand speech and images and text and videos and 3D
graphics and proteins. It's multimodal. It's also multi-model
meaning that it should be able to use any model that best fits the task. It is
multicloud by definition. Therefore, because these AI models are sitting in all these different places and it also
is hybrid cloud because if you're an enterprise company or you've built a robot or whatever that device is,
sometimes it's at the edge, sometimes a radio cell tower, maybe sometimes it's in an enterprise or maybe it's a place
where a hospital where you need to have the the data in real time right next to
you. Whatever those applications are, we know now this is what an AI application
looks like in the future. Or another way to think about that because future
applications are built on AIS. This is the basic framework of future
applications. This basic framework, this basic structure of agentic AIs that could do
the things that I'm talking about that is multi-model has now turbocharged
AI startups of all kinds. And now you can also because of the all of the open
models and all the tools that we provided you, you could also customize your AIs to teach your AI skills that
nobody else is teaching. Nobody else is causing their AI to become intelligent or smart in that way. You could do it
for yourself. And that's the work that we do with Neimotron, Nemo, and all of the things that we do with open models
is intended to do. You put a smart router in front of it. And that router is essentially a manager that decides
which one of the task based on the intention of the prompts that you give it, which one of the models is best fit
for that application for that solving that problem. Okay. So now when you
think about this architecture, what do you have? When you think about this architecture,
all of a sudden you have an AI that's on the one hand completely customizable by
you. Something that you could teach to do your own very skills for your company. Something that's domain secret,
something where you have deep domain expertise. Maybe you've got all of the data that you need to train that AI
model. On the other hand, your AI is always at the frontier by definition.
You're always at the frontier. On the one hand, you're always customized. On the other hand, it should just run. And
so, we thought we would make the simplest of examples to make it available to you. This entire framework
we call a blueprint and we have blueprints that are integrated into enterprise SAS platforms all over the
world and we're really pleased with the progress. But what we do is show you a a short example of something that anybody
can do. Let's build a personal assistant.
I wanted to help me with my calendar, emails, to-do lists, and even keep an eye on my home. I use Brev to turn my
DGX Spark into a personal cloud. So, I can use the same interface whether I'm using a cloud GPU or a DGX Spark. I use
a Frontier model API to easily get started.
I want him to help me with my emails, so I create an email tool for my agent to call.
I want my emails to stay private, so I'll add an open model that's running locally on the Spark.
Now, for any job, I want the agent to use the right model for the right task. So, I'll use an intentbased model
router. This way, prompts that need email will stay on my Spark, and everything else
can call the Frontier model. I want my assistant to interact with my world, so I'll hook it up to Hugging Faces Reachi
mini robot. My agent controls the head, ears, and camera of the Reachi with tool calls. I
want to give Reichi a voice, and I really like 11 Labs, so I'll hook up their API. Hi, I'm Reachi running on DGX Spark.
Hey Richi, what's on my to-do list today? your to-do list today.
Grab groceries, eggs, milk, butter, and send Jensen the new script.
Okay, let's send Jensen an update. Tell him we'll have it for him by the end of the day. We'll do.
Richi, there's a sketch, too. Can you turn it into an architectural rendering? Sure.
Nice. Now make a video and show me around the room.
Here you go. That's great. With Brev, I can share access to my
Spark and Reachi, so I'm going to share it with Anna. Hey Richi, what's Potato up to?
He's on the couch. I remember you don't like this. I'll tell him to get off. Potato, off the
couch. With all the progress in open source, it's incredible to see what you can build. I'd love to see what you create.
Isn't that incredible? Now, the amazing thing is that is
utterly trivial now. That is utterly trivial now. And yet, just a couple
years ago, all of that would have been impossible. Absolutely unimaginable. Well, this basic framework, this basic
way of building applications using language models
using language models. Using language models using language
models that are pre-trained and they're proprietary, they're frontier. combine
it with customized language models into a aentic framework, a reasoning
framework that allows you to access tools and files and maybe even connect
to other agents. This is basically the architecture of AI
applications or applications in the modern age and the ability for us to create these applications are incredibly
fast. And notice if you give it this application um
information that it's never seen before or in a structure that has is not
represented exactly as you thought it can still reason through it and make its
best effort to reason through the data the information to try to understand how to solve the problem artificial
intelligence. Okay. So this basic framework is now being integrated and and everything that I just described. We
had the benefit of working with some of the world's leading enterprise platform companies. Uh Palunteer for example
um their their entire AI and data processing platform is being integrated
accelerated by NVIDIA today. Service Now the world's leading customer service and
um employee service platform. Snowflake the world's top data platform in the
cloud. uh incredible work that that uh is being done there. Uh Code Rabbit,
we're using Code Rabbit all over Nvidia. Uh Crowdstrike creating AIs to detect to
find AI threats. Uh NetApp, their AI, their data platform now has NVIDIA's
semantic AI on top of it and agentic systems on top of it uh uh to for uh for
them to do customer service. But the important thing is this. Not only is this the way that you develop applications now, this is going to be
the user interface of your platform. So whether it's Palanteer or Service Now or
Snowflake and many other companies that we're working with, the agentic system
is the interface. It's no longer Excel with a bunch of, you know, squares that
you enter enter information into. Maybe it's no longer could just command line. the any all of that multimodality
information is now possible and the way you interact with your platform is much
more well if you will simple like you're interacting with people and so that's
enterprise AI being revolutionized by angentic systems the next thing is
physical AI this is an area that you've seen me talk about for several years in fact we've been working on this for
eight years the question is how do you take something that is intelligent
inside a computer and interacts with you with screens and speakers to something
that can interact with the world. Meaning it can understand the common sense of how the world works. Object
permanence. If I look away and I look back, that object is still there. Um causality. If I push it, it tips over.
It understands friction and gravity. It understands inertia. that a heavy truck
rolling down the road is going to need a little bit more time to stop, that a
ball is going to keep on rolling. These ideas are common sense to even a
little child, but for AI, it's completely unknown. And so we have to
create a system that allows AIS to learn the the common sense of the physical world, learn its laws, but also to be
able to of course learn from data and the data is quite scarce and to be able to evaluate whether that AI is working,
meaning it has to simulate in an environment. How does an AI know that
the the actions that it's performing is consistent with what it should do if it doesn't have the ability to simulate the
response of the physical world back on its actions. The response of its actions is really important to simulate
otherwise there's no way to evaluate it. It's different every time. And so this basic system requires three computers.
One computer of course the one that we know that Nvidia builds for training the AI models. Another computer that we know
is to inference the computer. Inference the models. Inferencing the model is essentially a robotics computer that
runs in a car or runs in a robot or runs in a factory, runs anywhere at the edge. But there has to be another computer
that's designed for simulation and simulation is at the heart of almost everything Nvidia does. This is this is
where we are most comfortable and simulation was really the foundations of
almost everything that we've done with physical AI. So we have three computers and multiple stacks that run on these
computers, these libraries to make them useful. Omniverse is our digital twin physically based simulation world.
Cosmos as I mentioned earlier is our foundation model not a foundation model for language but a foundation model of
the world. and is also aligned with language. You could say something like, you know,
what's happening to the ball and they they'll tell you the ball's rolling down the street. And so a world foundation
model and then of course the robotics models. We have two of them. One of them is called Groot. The other one's called
Alpamo that I'm going to tell you about. Now the one of the most important things that we have to do with physical AI is
to create the data to train the AI in the first place. Where does that data come from? rather than instead of having
languages because we created a bunch of text that are what we consider ground
truth that the AI can learn from. How do we teach an AI the ground truth of physics? There lots and lots of videos,
lots and lots of videos, but hardly enough to capture the diversity and the type of interactions that we need. And
so this is where great minds came together and transformed
what used to be compute into data. Now using synthetic data generation that is
grounded and conditioned by the laws of physics, grounded and conditioned by
ground truth, we can now selectively cleverly generate data that we can then
use to train the AI. So for example, what comes into this AI, this Cosmos AI
world model on the left on over here is the output of a traffic simulator.
Now this traffic simulator is hardly enough for an AI to learn from. We can take this, put it into a
Cosmos foundation model and generate surround video that is physically based
and physically plausible that the AI can now learn from. And there are so many
examples of this. Let me show you what Cosmos can do.
The chat GPT moment for physical AI is nearly here, but the challenge is clear.
The physical world is diverse and unpredictable. Collecting real world training data is
slow and costly and it's never enough. The answer is synthetic data. It starts
with NVIDIA Cosmos, an open Frontier World Foundation model for physical AI
pre-trained on internet scale video, real driving and robotics data, and 3D
simulation. Cosmos learned a unified representation of the world, able to align language,
images, 3D, and action. It performs physical AI skills like
generation, reasoning, and trajectory prediction from a single image. Cosmos generates
realistic video from 3D scene descriptions, physically
coherent motion, from driving telemetry and sensor logs,
surround video from planning simulators,
multi- camera environments, or from scenario prompts. It brings edge
cases to life. Developers can run interactive closed loop simulations in Cosmos. When actions
are made, the world responds. Cosmos reasons.
It analyzes edge scenarios, breaks them down into familiar physical interactions, and reasons about what
could happen next. Cosmos turns compute into data, training
AVs for the longtail and robots how to adapt for every scenario.
I know it's incredible. Cosmos is the world's leading foundation
model. World foundation model. It's been downloaded millions of times, used all over the world, getting world getting
the world ready for this new era of physical AI. We use it ourselves as well. We use it ourselves to create our
self-driving car. using it for scenario generation and
using it for evaluation. We could have something that allows us to effectively travel billions,
trillions of miles, but doing it inside a computer. And we've made enormous
progress. Today, we're announcing Alpio, the world's first
thinking reasoning autonomous vehicle AI. Alpo is
trained end to end. Literally from camera in to actuation out. The camera
in lots and lots of miles that are driven by itself where we human drive it dri using human
demonstration and we have lots and lots of miles that are generated by cosmos. In addition to
that, hundreds of thousands of examples are labeled very very carefully so that
we could teach the car how to drive. Alpha Mayo does something that's really special. Not only does it take sensor
input and activates steering wheel, brakes and and acceleration, it also
reasons about what action it is about to take. It tells you what action it's
going to take. the reasons by which it came about that action and then of course the trajectory.
All of these are coupled directly and trained very specifically by a large
combination of human trained and as well as Cosmos generated data. The result of
it is just really incredible. Not only does your car drive as you would expect it to drive and it drives so naturally
because it learned directly from human demonstrators but in every single scenario when it comes up to the
scenario it reasons about it tells you what it's going to do and it reasons about what you what's about to do. Now
the reason why this is so important is because of the long tale of driving there. It's impossible for us to simply
collect every single possible scenario for everything that could ever happen in every single country in every single
circumstance that's possibly ever going to happen for all of population.
However, it is very unlikely. It's very likely that every scenario if decomposed
into a whole bunch of other smaller scenarios are quite normal for you to understand. And so these long tails will
be decomposed into quite normal circumstances that the card knows how to deal with. It just needs to reason about
it. And so let's take a look. Everything you're about to see is one shot. It's a no hands.
Routing to your destination. Buckle up.
Heat.
Heat. Heat. Heat.
Heat. Heat.
Heat. Heat.
Heat. Heat.
Heat. Heat.
You have arrived.
We started working on self-driving cars eight years ago. And the reason for that is because we reason early on that deep
learning and artificial intelligence was going to reinvent the entire computing stack. And if we were ever going to
understand how to navigate ourselves and how to guide the industry towards this
new future, we have to get good at building the entire stack. Well, as I
mentioned earlier, AI is a five layer cake. The lowest layer is land power and
shell. In the case of robotics, the lowest layer is the car. The next layer above it is chips, GPUs, networking
chips, CPUs, all that kind of stuff. The next layer above that is the infrastructure.
That infrastructure in this particular case as I mentioned with physical AI is omniverse and cosmos.
And then above that are the models. And in the case of the models above that I
just shown you. The model here is called Alpha Mayo. And
Alpha Mayo today is open sourced. We this incredible body of work. It took
several thousand people. Our AV team is several thousand people. Just to put in perspective, our partner uh Ola, I think
Ola's here in the audience somewhere. Uh Mercedes agreed to partner with us five
years ago to go make all of this possible. We imagine that someday a
billion cars on a road will all be autonomous. You could either have it be a robo taxi that you're you're you're
orchestrating and and renting from somebody or you could own it and is driving for driving by itself or you
could decide to drive for yourself and so but every single car will have autonomous vehicle capability. Every
single car will be AI powered and so the the the model layer in this case is
Alpha Mayo and the application above that is the Mercedes-Benz. Okay. And so, so this entire stack is
our first Nvidia first entire stack endeavor and we've been working on it for this entire time and I'm just so
happy that the first AV car from Nvidia is going to be on the road in Q1 and
then it goes Europe in Q2 here in the United States in Q1 then Europe in Q2 and I think it's Asia in Q3 and Q4 and
the powerful thing is that we're going to keep on updating it with next ver next versions of alpha Mayo and versions
after that. There's no question in my mind now that this is going to be one of the largest robotics industries and I'm
so happy that we worked on it and it taught us enormous amount about how to help the rest of the world build robotic
systems. That deep understanding in knowing how to build it ourselves, building the entire infrastructure
ourselves and knowing what kind of chips a robotic system would would need. In this partic particular case, dual Orins,
the next generation dual Thors. These processors are designed for robotic
systems and was designed for the safe highest level of safety capability. This
car just got rated. It just went to production. The Mercedes-Benz CLA was
just rated by NCAP, the world's safest car.
It is the only system that I know that has every single line of code, the chip,
the system, every line of code safety certified. The entire model system is
based on a sensors are diverse and redundant and so is the self-driving car
stack. The Alpha Mayo stack is trained end to end and has incredible skills.
However, nobody knows until you drive it forever that it's going to be perfectly safe.
And so that we the way we guard rail that is with another software stack, an entire AV stack underneath. That entire
AV stack is built to be fully traceable and it's taken us some five years to
build that some six, seven years actually to build that second stack. These two software stacks are mirroring
each other and then we have a policy and safety evaluator decide is this something that I'm very confident and
can reason about driving very safely. If so, I'm going to have Alpamo do it. If it's a circumstance that I'm not very
confident in and the safety um policy evaluator decide that we're going to go
back to a a very a simpler, safer guard rail system, then it goes back to the classical AV stack. where the only car
in the world with both of these AV stacks running and all safety systems should have diversity and redundancy.
Well, our vision is that someday every single car, every single truck will be autonomous. And we've been working
towards that future. This entire stack is vertically integrated. Of course, in the case of Mercedes-Benz, we built the
entire stack together. We're going to deploy the car. We're going to operate the stack. We're going to maintain the stack for as long as we shall live.
However, like everything else we do as a company, we build the entire stack, but
the entire stack is open for the ecosystem. And these the ecosystem working with us to build L4 and robo
taxis is expanding and it's going everywhere. I fully expect this to be well this is
already a giant business for us. It's a giant business for us because they use it for training our training data,
processing data and training their models. They use it for synthetic data generation in some cases. In some car,
in some companies, they pretty much just build uh the computers, the chips that are inside the car. And some companies
work with us full stack. Some companies work with us some partial part of that. Okay. So, it doesn't matter uh how much
you decide to use. You know, my only request is use a little bit of video wherever you can and uh you know, but uh
the entire thing is open. Now this is going to be the first largecale
mainstream um AI physical AI market and this is now I think we can all agree
fully here and this inflection point of going from not autonomous vehicles to
autonomous vehicles is probably happening right about this time in in the next 10 years I'm fairly certain a
very very large percentage of the world's cars will be autonomous or highly autonomous but this This basic
technique that I just described in using the three computers using synthetic data generation and simulation applies to
every form of robotic systems. It could be a robot that is just an articulator, a manipulator, maybe it's a mobile
robot, maybe it's a fully humanoid robot. And so the next journey,
the next era for robotic systems is going to be, you know, robots. And these
robots are going to come in all kinds of different sizes. And and uh I invited some friends. Did they come?
Hey guys, hurry up. I got a lot of stuff to cover.
Come on, hurry. Did you tell R2-D2 you were going to be
here? Did you? And C3PO.
Okay. All right. Come here. Before now, one of the things that one of the things that's really You have Jetson's. They
have little Jetson computers inside them. They're trained inside Omniverse.
And how about this? Let's show everybody the simulator that you were that you guys learned how to how to be robots in.
You You guys want to look at that? Okay, let's look at that. Run it, please.
See?
Is it amazing? That's how you learn to be a robot. You
did it all inside Omniverse. And the robot simulators called Isaac. Isaac Sim
and Isaac Lab. And anybody who wants to build a robot, you know, nobody could nobody's going to be as cute as you. But
now we have all Look at all these look at all these friends that we have building robots. We have We're building
big ones. No, like I said, nobody's as cute as you guys are. But we have Neurobot and we have we have Agubot.
Agubot over there, you know. We have uh uh LG over here. They just announced a
new robot. Caterpillar. They've got the largest robots ever. That one delivers
food to your house. That's connected to Uber Eats. And that's Surf Robot. I love those guys. Agility. Boston Dynamics.
Incredible. You got surgical robots. You got manipulator robots from Franka.
You got universal robotics robot. Incredible number of different robots. And so this is the next chapter. We're
going to talk a lot more about robotics in the future. But it's not just about the robots in the end. I know
everything's about you guys. It's about getting there. And one of the air one of the most important industries in the
world that will be revolutionized by physical AI and AI physics
is the industry that started all of us. at NVIDIA. It wouldn't be possible if
not for the companies that I'm about to talk to. And I'm so happy that all of them starting with Cadence is going to
accelerate everything. Cadence CUDA X integrated into all of their simulations and solvers. They've got uh NVIDIA
physical physical AIs that they're going to use for uh for different um physical plants and plant simulations. You got AI
physics being integrated into these systems. So whether it's an EDA or SDA
um and in the future robotic systems, we're going to have basically the same technology that made you guys possible
now completely revolutionize these design stacks. Synopsis without Synopsis, you know, synopsis and cadence
are completely completely indispensable in the world of chip design. uh synopsis
is uh leads in uh in uh logic design and and IP uh in the case of cadence they
lead physical design the place and route uh and emulation and verification.
Cadence is incredible at emulation and verification. Both of them are moving into the world of system design and
system simulation. And so in the future we're going to design your chips inside
Cadence and inside Synopsis. We're going to design your systems and emulate the whole thing and simulate everything
inside these tools. That's your future. We're going to give Yeah. You're going to be born inside these inside these
platforms. Pretty amazing, right? And so we're so happy that we're working with these these industries just as we've
integrated NVIDIA into Palunteer and Service Now. We're integrating Nvidia
into the most computationally intensive simulation industries, Synopsis and
Cadence. And today we're announcing that Seammens is also doing the same thing. We're going to integrate CUDA X physical
AI agentic AI Nemo Neotron deeply integrated into the world of Seammens.
And the reason for that is this. First, we designed the chips
and all of it in the future will be accelerated by Nvidia. You're going to be very happy about that. We're going to have Agentic chip designers and system
designers working with us, helping us do design just as we have agentic software
engineers helping our software engineers code today. And so we'll have agentic chip designers and system designers.
We're going to create you inside this. But then we have to build you. We have
to build the plants, the factories that make manufacture you. We have to design
the manufacturing lines that assemble all of you. And these manufacturing plants are going to be essentially
gigantic robots. Incredible, isn't that right? I know. I know. And so, you're going to
be designed in a computer. You're going to be made in a computer. You're going to be tested and evaluated in a computer
long before long before you have to spend any time dealing with gravity.
I know. Do you know how to deal with gravity? Can you jump?
Can you jump?
Okay. All right. Don't show off. Okay. So, so this so now
the industry the industry that made Nvidia possible. We're I'm just so happy
that that now the technology that we're creating is at a level of sophistication and capability that we can now help them
revolutionize their industry. And so what started with with uh with them, we
now have the opportunity to go back and and help them revolutionize theirs. Let's take a look at the stuff that we're going to do with Seammens.
Come on. Breakthroughs in physical AI are letting AI move from screens to our physical
world. And just in time, as the world builds factories of every kind for chips,
computers, life-saving drugs, and AI, as the global labor shortage worsens, we
need automation powered by physical AI and robotics more than ever.
This where AI meets the world's largest physical industries is the foundation of NVIDIA and Seaman's partnership. For
nearly two centuries, Seammens has built the world's industries and now it is reinventing it for the age
of AI. Semens is integrating NVIDIA CUDA X
libraries, AI models, and Omniverse into its portfolio of EDA,
CAE, and digital twin tools and platforms.
Together, we're bringing physical AI to the full industrial life cycle.
From design and simulation to production
and operations, we stand at the beginning of a new industrial revolution, the age of
physical AI built by Nvidia and Seammens for the next age of industries.
Incredible, right guys? What do you think? All right. Well, hang
on tight. Just hang on tight. And so, so this is, you know, if you look at look
at the world's models, there's no question OpenAI is the the the leading
token generator today. More to more open AAI tokens are generated than just about anything else. The second largest group,
the second largest probably open models. And my guess is that over time because there are so many companies, so many
researchers, so many different types of domains and modalities that open-source models will be by far the largest. Let's
talk about somebody really special. You guys want to do that? Let's talk about Vera Rubin.
Vera Rubin. Yeah, go ahead. She's a American astronomer.
She was the first to observe. She noticed that the tails of the galaxies
were moving about as fast as the center of the galaxies. Well, I know it makes
no sense. It makes no sense. Newtonian physics would say just like the solar system, the planets further away from
the sun is circulating circ cir circling the sun slower than the planets closer
to the sun. And therefore it makes no sense that this happens unless there's
invisible bodies we call them she discovered dark body dark matter um that
occupy space even though we don't see it and so Vera Rubin is the person that we
named our next computer after. Isn't that a good idea?
I know. Okay. Okay, Vera Rubin is designed to
address this fundamental challenge that we have. The amount of computation necessary for AI is skyrocketing. The
demand for NVIDIA GPUs is skyrocketing. It's skyrocketing because models are increasing by a factor of 10, an order
of a magnitude every single year. And not to mention, as I mentioned, 01's
introduction was an inflection point for AI. Instead of a oneshot answer,
inference is now a thinking process. And in order to teach the AI how to think,
reinforcement learning and very significant computation was introduced
into post training. It wasn't no long it's no longer supervised fine-tuning or
otherwise known as imitation learning or supervision training. You now have reinforcement learning
essentially the computer trial trying different iterations itself learning how to perform a task. The amount of
computation for pre pre-training for post- trainining for test time scaling has exploded as a result of that. And
now every single inference that we do instead of just one shot the number of tokens you could just see the AI think
which we appreciate. The longer it thinks oftentimes it produces a better answer. And so test time scaling causes
the number of tokens to be generated to increase by 5x every single year. Not to
mention, meanwhile, the race is on for AI. Everybody's trying to get to the
next level. Everybody's trying to get to the next frontier. And every time they get to the next frontier, the last
generation AI tokens, the cost starts to starts to decline about a factor of 10x
every year. The 10x decline every year is actually telling you something different. It's saying that the race is
so intense. Everybody's trying to get to the next level and somebody is getting to the next level. And so therefore, all
of it is a computing problem. The faster you compute, the sooner you can get to the next level of the next frontier. All
of these things are simultaneously happening at the same time. And so we decided that we have to advance
the state-of-the-art of computation every single year. Not one year left
behind. And now we've been shipping GB200s
year and a half ago. Right now we're in fullcale manufacturing of GB300.
And if Vera Rubin is going to be in time for this year, it must be in production
by now. And so today I can tell you that Vera Rubin is in full production.
You guys want to take a look at Vera Rubin? All right, come on. Play it, please.
Vera Rubin arrives just in time for the next frontier of AI.
This is the story of how we built it. The architecture, a system of six chips
engineered to work as one, born from extreme code design. It begins with Vera, a custom-designed CPU, double the
performance of the previous generation. And the Reuben GPU, Vera and Reuben are
co-designed from the start to birectionally and coherently share data faster and with lower latency.
Then 17,000 components come together on a Ver Rubin compute board.
High-speed robots place components with micron precision before the Vera CPU and
two Reuben GPUs complete the assembly. Capable of delivering 100 pedaflops of
AI, five times that of its predecessor.
AI needs data fast. Connect X9 delivers 1.6 6 terabs per
second of scale out bandwidth to each GPU.
Bluefield 4 DPU offloads storage and security so compute stays fully focused
on AI. The Vera Rubin compute tray completely redesigned with no cables, hoses, or
fans. Featuring a Bluefield 4 DPU, eight Connect X9 Nix, two Vera CPUs, and four
Reuben GPUs, the compute building block of the Vera Rubin AI supercomputer.
Next, the sixth generation MVLink switch, moving more data than the global
internet, connecting 18 compute nodes, scaling up to 72 Reuben GPUs, operating
as one. Then Spectrum X Ethernet Photonix,
the world's first Ethernet switch with 512 lanes and 200 Gbit capable
co-packaged optics scale out thousands of racks into an AI factory.
15,000 engineer years since design began, the first Vera Rubin MVL 72 rack
comes online. Six breakthrough chips, 18 compute trays, nine MVLink switch trays,
220 trillion transistors weighing nearly two tons.
One giant leap to the next frontier of AI. Reuben is here.
What do you guys think?
This is a Reuben pod. 1152 GPUs
in 16 racks. Each one of the racks as you know has uh 72
Vera Rubin or 72 Reubins. Each one of the Reubins is two actual GPU dies
connected together. I'm going to show I'm going to show it to you, but there are several things that Well, I'll tell
you later. I can't tell you everything right away.
Well, we designed six different chips. First of all, we have a rule inside our company, and it's a good rule. No new
generation should have more than one or two chips change. But the problem is
this. As you could see, we were describing the total number of transistors in each one of the chips
that were being described. And we know that Moore's law has largely slowed. And so the number of transistors we can get
year after year after year can't possibly keep up with the 10 times
larger models. It can't possibly keep up with five times per year more tokens
generated. It can't possibly keep up with the fact that cost decline of the
tokens are going to be so aggressive. It is impossible to keep up with those kind of rates if the indust for the industry
to continue to advance unless we deployed aggressive extreme code design
basically innovating across all of the chips across the entire stack all at the
same time. which is the reason why we decided that this generation we had no choice but to design every chip over
again. Now every single chip that we were describing just now can be a press conference in all in itself and there's
an entire company who's probably dedicated to doing that back in the old days. Each one of them are completely
revolutionary and the best of its kind. The Vera CPU I'm so proud of it in a
power constrained world. Gray CPU is two times the performance in a power
constrained world. It's twice the performance per watt of the world's most advanced CPUs. Its data rate is insane.
It was designed to process supercomputers and Vera was an
incredible GPU. Grace was an incredible GPU. Now Vera increases the
singlethreaded performance, increases the capacity of the memory, increases everything just dramatically. It's a
giant chip. This is the Vera CPU. This is one CPU.
And this is connected to the Reuben GPU. Look at that thing.
It's a giant chip. Now, the thing that's really special, and I I'll go through these. It's going to take three hands, I
think, four hands to do this. Okay. So, this is the Ver Vera CPU. It's got 88
CPU cores. And the CPU cores are designed to be multi-threaded. But the multi-threaded nature of of uh Vera was
designed so that each one of the 176 threads could get its full full
performance. So it's essentially as of there's 176 cores but only 88 physical cores. So these cores were designed in
in using a technology called spatial multi-threading. But the IO performance is incredible. This is the Reuben GPU.
It's 5x blackwell in floating performance. But the important thing is go to the bottom line. The bottom line
it's only 1.6 times the number of transistors of black wall. That kind of tells you something about the the levels
of semiconductor physics today. If we don't do code design, if we do don't do
extreme code design at the level of basically every single chip across the entire system, how is it
possible we deliver performance levels that is, you know, at best one point 1
1.6 times each year? Because that's the total number of transistors you have. And even if you were to have a little
bit more um performance per transistor, say 25%, you're this impossible to get a
100% yield out of the number of transistors you get. And so 1.6x kind of puts a ceiling on how far performance
can go each year unless you do something extreme. And we call it extreme code design. Well, one of the things that one
of the things that we did and it was a great invention. It's called MVF FP4 tensor core. The transformer engine
inside our chip is not just a 4bit floatingoint number somehow that we put into the data path. It is an entire
processor, a processing unit that understands how to dynamically
adaptively adjust its precision and structure to deal with different levels
of the transformer so that you can achieve higher throughput wherever it's possible to lose precision and to go
back to the highest possible precision wherever you need to. That ability to dynamically do that. You can't do this
in software because obviously it's just running too fast. And so you have to be able to do it adaptively inside the
processor. That's what an MVF FP4 is. When somebody says FP4 or FP8, it almost
means nothing to us. And the reason for that is because it's the tensor core structure in all of the algorithms that
makes makes it work. MV FP4, we've published papers on this already. The precision that the the level of
throughput and precision it's able to retain is in and completely incredible. This is groundbreaking work. I would not
be surprised that the industry would like us to make this format and this structure an industry standard in the
future. This is completely revolutionary. This is how we were able to deliver such a gigantic step up in
performance even though we only have 1.6 times the number of transistors. Okay.
So this is and now once you have a great processing node and this is the processor node and inside so this is
this is for example here let me do this
is this is wow it's super heavy you have to be a CEO in really good shape to do
this job okay all right so this thing is I'm
gonna guess this is probably I don't know couple of hundred pounds.
I thought that was funny too. Come on. It could have been. Everybody's
gone. No, I don't think so. All right. So So look at this. This is
the last one. We revolutionized the entire MGX chassis. This node
43 cables, zero cables, six tubes,
z just two of them here. It takes two hours to assemble this.
If you're lucky, it takes two hours. And of course, you're probably going to assemble it wrong. You're gonna have to
retest it, test it, reassemble it. So, the assembly process is incredibly complicated. And it was understandable
as one of our first supercomputers that's deconstructed in this way. This from two hours to 5 minutes.
80% liquid cooled. 100% liquid cooled.
Yeah. Really, really a breakthrough. Okay. So, so this is the new compute
chassis and what connects all of these to the top of rack switches, the east
west traffic is called the Spectrumx nick. This is the world's best nick.
Unquestionably, Nvidia's Melanox, the acquisition Melanox that joined us a long time ago now. Um, this their
networking technology for high performance computing is the world's best bar none. the algorithms, the chip
design, all of the interconnects, all the software stacks that run on top of it, their RDMA, absolutely absolutely
bar none, the world's best. And now it has the ability to do programmable RMDMA and data path accelerator so that our
partners like AI labs could create their own algorithms for how they want to move data around the system. But this is
completely world worldclass connect X9 and the Vera CPU were co-designed and
we never revealed it. not never never released it until CX9 came along because
we we co-designed it for a new type of processor. You know, Connect X9 or CX8 and Spectrum
X revolutionized how Ethernet was done for artificial intelligence. Ethernet
traffic for AI is much much more intense, requires much lower latency.
The the instantaneous surge of traffic is unlike anything Ethernet sees. And so
we created Spectrum X which is AI Ethernet. Two years ago we announced Spectrum X.
NVIDIA today is the largest networking company the world has ever seen. So it's
been so successful and used in so many different installations. It is just sweeping uh the AI landscape. The
performance is incredible especially when you have a 200 um megawatt data
center or if you have a gigawatt data center. These are billions of dollars. Let's say a gigawatt data center is $50
billion. If the networking performance allows you to deliver an extra 10%
in the case of Spectrum X, delivering 25% higher throughput is not uncommon.
If we were to just deliver 10% that's worth $5 billion. The networking is
completely free, which is the reason why, well, everybody uses Spectrum X. It's just an
incredible thing. And now we're going to invent a new type a new type of uh uh
data processing. And so spectral is for east west traffic. We now have a new
processor called blue field 4. Blue field 4 allows us to take a large large very large data center isolate different
parts of it so that different users could use different parts of it. Make sure that everything could be virtualized if they decide to be
virtualized. So you offload a lot of the um virtualization software, the security
software, the networking software for your north south traffic. And so Bluefield 4 comes standard with every
single one of these compute nodes. Bluefield 4 has a second application I'm going to talk about in just a second.
This is a revolutionary processor and I'm so excited about it. This is the MVLink 6 switch
and it's right here. This is the this switch. This switch
chip there are four of them inside the MVLink switch here. Each one of these switchips has the
fastest certis in history. The world is barely getting to 200 Gbits. This is 400
Gbits per second switch. The reason why this is so important is so that we could
have every single GPU talk to every other GPU at exactly the same time. This
switch, this switch on the back plane of one of these racks enables us to move
the equivalent of twice the amount of the global internet data,
twice as all of the world's internet data at twice the speed. You take the
cross-sectional bandwidth of the entire planet's internet, it's about 100 terabytes per second. This is 240
terabytes per second. So it kind of puts it in perspective. This is so that every single GPU can work with every single
other GPU at exactly the same time. Okay. Then on top of that
on top of that okay so this is one rack. This is one rack. Each one of the racks as you could see the number of
transistors in this one rack is 1.7 times.
Yeah. Could you do this for me? So, this is it's usually about two tons, but
today it's two and a half tons because um when they shipped it, they forgot to drain the water out of it.
So, we we shipped a lot of water from California.
Can you hear it squealing? You know, when you're rotating two and a half tons,
you got to squeal a little. Oh, you could do it. Wow.
Okay, we just we won't make you do that twice. All right. So, so um so behind
behind this are the MVLink spines. Basically, two miles of copper cables.
Copper is the best conductor we know. And these are all shielded copper cables, structured copper cables, the
most the world's ever used in computing systems ever. and and um uh our certis
drive the copper cables from the top of the rack all the way to the bottom of the rack at 400 gigabits per second.
It's incredible. And so uh this has 2 miles of total copper cables, 5,000 copper cables. And this makes the MVLink
uh spine possible. This is the revolution that that really started the NGX system. Now we we decided that we
would create an industry standard system so that the entire ecosystem all of our supply chain could standardize on these
components. There some 80,000 different components that make up this
these MGX systems and it's a total waste if we were to change it every single year. every single major computer
company from Foxcon to Quanta to Wistron, you know, the list goes on and on and on to HP and Dell and Lenovo,
everybody knows how to build these systems. And so the fact that we could squeeze Ruben Vera Rubin into this even
though the performance is so much so much higher and very importantly the power is twice as high. The power of
Vera Rubin is twice as high as Grace Blackwell. And yet, and this is the
miracle, the air that goes into it, the the air flow is about the same. And very
importantly, the water that goes into it is the same temperature, 45° C. With 45°
C, no water chillers are necessary for data centers. We're basically cooling
this supercomput with hot water. is so incredibly efficient. And so
this is um this is the new the new rack. 1.7 times more transistors, but five
times more peak inference performance, three and a half times more peak u uh uh
training performance. Okay, they're connected on top using Spectrum
X. Oh, thank you.
This is this is the world's first manufacturing chip using uh TSMC's
new process that we co-inovated called coupe. It's a silicon photonix integrated silicon photonix process
technology. And this allows us to take silicon photonix directly right to the
chip. And this is 512 ports at 200 Gbits per second. And this is the new Ethernet
AI switch, the Spectrum X Ethernet switch. And look at this giant chip. But what's really amazing, it's got silicon
photonics directly connected to it. And lasers come in.
Lasers come in through here. Lasers come in through here. The optics are here and
they connect out to the rest of the data data center. This I'll show you in a second, but this is on top of the rack.
And this is the new Spectrum X um silicon photonic switch. Okay.
And we have something new I want to tell you about. So just as I mentioned a couple years ago,
we introduced Spectrum X so that we could reinvent the way that networking is done. Um Ethernet is really easy to
manage and everybody has an Ethernet stack and every data center in the world knows how to deal with Ethernet. Um and
the only thing that we were we were using at the time was called Infiniband which is used for supercomputers.
Infiniband is very low latency. Um but of course the software stack the entire
manageability of Infiniband is very alien to the people who use Ethernet. So we decided to enter the Ethernet switch
market for the very first time. Spectrum X that just took off and it made us the
largest networking company in the world. As I mentioned, this next generation spectrum is going to carry on that
tradition. But just as I said earlier, AI has reinvented the whole computing
stack, every layer of the computing stack. It stands to reason that when AI
starts to get deployed in the world's enterprises, it's going to also reinvent the way storage is done. Well, AI
doesn't use SQL. AI use semantics information. And when AI is being used,
it creates this temporary knowledge, temporary temporary memory calls KV cache, K key value combinations, but
it's a KV cache. Basically, the cache of the AI, the working memory of the AI. And the working memory of the AI is
stored in the HBO memory. Every single token, for every single token,
the H the GPU reads in the model, the entire model. It reads in the entire
working memory and it produces one token and it stores that one token back into
the KV cache and then the next to the next time it does that it reads in the entire memory reads it and it streams it
through our GPU and then generates another token. Well, it does this repeatedly token after token after token
and obviously if you have a long conversation with that AI over time that memory that context memory is going to
grow tremendously. Not to mention the models are growing. The number of turns that we're using, the AI are are
increasing. We would like to have this AI stay with us our entire life. And remember, every single conversation
we've ever had with it, right? Every single lick of research that I've asked it for. Of course, we the number of
people that will be sharing the supercomputer is going to continue to grow. And so this context memory, which
started out fitting inside an HBM, is no longer large enough. Last year we
created Grace Blackwell's very fast memory we called fast context
memory in that's the reason why we connected grace directly to hopper
that's why we connected grace directly to blackwell so that we can expand the context memory but even that is not
enough and so the next solution of course is to go off onto the network the north south network off to the storage
of the company but if you have a whole lot of AIs running at the same time that
network is no longer going to be fast enough. So the answer is very clearly to do it different. And so we intro we
created Bluefield 4 so that we could essentially have a very fast KV cache
context memory store right in the rack. And so I'll show you in just one second,
but there's a whole new category of storage systems. And the industry is so
excited because this is a pain point for just about everybody who does a lot of token generation today. the AI labs, the
cloud service providers, they're really suffering from the amount of network traffic that's causing being caused by
KV cache moving around. And so the idea that we would create a new platform, a new processor to run the entire Dynamo
KV cache context memory management system and to put it very close to the
rest of the rack is completely revolutionary. So this is it. This is it sits right here.
So this this is all the compute nodes. Each one of these is MVLink 72. So this
is Vera Rubin MVLink 72 144 U R Reuben GPUs. This is the context
memory that's stored here. Behind each one of these are four blue fields. Behind each blue field is 150 gigab 150
terabytes 150 terabytes of memory context memory. And for each GPU once you allocate it
across each GPU will get an additional 16 terabytes. Now inside this node each
GPU essentially has one terabyte. And now with this backing store here
directly on the same east west traffic at exactly the same data rate 200 gigabits per second across literally the
entire fabric of this compute node. you're going to get an additional 16 terabytes of memory. Okay. And this is
the management plane. These are these are the spectrum X
switches that connects all of them together. And over here, these switches at the end
connects them to the rest of the data center. Okay. And so this is the Vera
Rubin. Now there are several things that's really incredible about it. So the first thing that I mentioned is that
the this entire system is twice the
energy efficiency essentially the that twice the the the temperature performance in the sense that that even
though the power is twice as high the amount of energy used is twice as high the amount of computation is many times
higher than that but the liquid that goes into it still 45 degrees C that
enables us to save about 6% % of the world's data center power. So that's a very big deal. The second very big deal
is that this entire system is now confidential computing safe. Meaning everything is encoded in transit at rest
and during compute and every single bus is now encrypted. every PCI Express,
every MV link, every H you know for a MVL link between CPU me and GPU between
GPU to GPU, everything is now encrypted and so it's confidential computing safe.
This allows companies to feel safe that their models are being deployed by
somebody else but it will never be seen by anybody else. Okay. And so this particular system is not only incredibly
energy efficient and there's one other thing that's incredible because of the nature of the workload of
AI it spikes instantaneously with this computation layer called all
reduce the amount of current the amount of energy that is used but
simultaneously is really off the charts. Oftentimes it'll spike up 25%. We now
have power smoothing across the entire system so that you don't have to overprovision by 25 times or if you
overprovision by 25 times you don't have to leave 25 times 25% 25% not 25 times
25% of the energy um squandered or unused and so now you could fill up the
entire power budget and you don't have to over you don't have to proceed you don't have to provision beyond that and
then the Last thing of course is performance. So let's take a look at the performance of this. These are only
charts that people who build AI super supercomputers would love. It took exact
it took every single one of these chips complete redesign of every single one of the systems and rewriting the entire
stack for us to make this possible. Basically this is training the AI model. This
first column, the faster you train AI models, the faster you can get the next
frontier out to the world. This is your time to market. This is technology leadership. This is your pricing power.
And so in the case of the green, this is essentially
a 10 trillion parameter model. We scaled it up from deepse deepse. That's why we
call it deepsee++ a training a 10 trillion parameter model on a 100
trillion tokens. Okay. And that's this is our simulation projection of what it
would take for us to build the next frontier model. The next frontier model uh Elon's already mentioned that the
next version of Grock Grock 5 I think is 7 trillion parameters. This is 10 and in
the green is black. Well, and here in the case of um uh Reuben, notice the
throughput is so much higher and therefore it only takes 1/4th as many of these systems in order to train the
model in the time that we gave it here which is one month. Okay. And so time
time is the same for everybody. Now how much how fast you can train that model and how large of a model you can train
is how you're going to get to the frontier first. The second part is your factory throughput.
Blackwell is green again. And factory throughput is important because your factory is in the case of a gigawatt is
$50 billion. A $50 billion data center
can only consume one gigawatt of power. And so if your performance, your
throughput per watt is very good versus quite poor, that directly translates to
your revenues. Your revenues of your data center is directly related to the
second second column. And in the case of Blackwell, it was about 10 times over
Hopper. In the case of Reuben, it's going to be about 10 times higher again. Okay. And in the case of now the um the
cost of the tokens, how cost effectively it is to generate the token. This is
Reuben about one/10enth just as in the case of Yep.
So that's how this is how we're going to get everybody to the next frontier to um push AI to the next level and of
course to build these data centers energy efficiently and cost efficiently.
So this is it. This is Nvidia today. You know, we mentioned that we build chips,
but as you know, Nvidia builds entire systems now. And AI is a full stack. We
we're reinventing AI across everything from chips to infrastructure to models
to applications. And our job is to create the entire stack so that all of you could create incredible applications
uh for the rest of the world. Thank you all for coming. Have a great CES. Now,
before before I before I let you guys go, uh there were a whole bunch of slides we had to cut we had to leave on
the cutting floor and so we have some out takes here. I think it'll be fun for you. Have a great CES, guys.
And cut. Nvidia live at CES. Take four. Marker.
Boom. Mike action.
Sorry guys. Platform shift, huh?
That should do it. And let's roll camera.
A shade of green. A bright happy green. World's most powerful AI supercomput you
can plug into the wall next to my toaster.
Hey guys, I'm I'm stuck again. I'm so sorry. This slide is never going to work. Let's just cut it. Hello. Can you hear me?
So, like I was saying, the router. Because not every problem needs the biggest, smartest model. Just the right
one. No, no, don't lose any of them. This new six chip Reuben platform makes
one amazing AI supercomputer. There you go, little guy.
Oh no, no, not the scaling laws. There is a squirrel on the car. Be ready
to make the squirrel go away. Ask the squirrel gently to move away. Did you know the best models today are
all mixture of experts? Hey
Where'd everybody go?

## 中文翻译
好的，我将为您提供整篇演讲稿的完整逐句翻译，不遗漏任何细节，并按照 Markdown 格式输出。

---

# 黄仁勋 2026 CES 主题演讲全文（中英对照版）

## 1. 开场与欢迎

**Welcome to the stage, Nvidia founder and CEO, Jensen Huang.**
欢迎 NVIDIA 创始人兼首席执行官黄仁勋登台。

**Hello, Las Vegas. Happy New Year.**
你好，拉斯维加斯。新年快乐。

**Welcome to CES. Well, we have about 15 kilos worth of material to pack in here. I'm so happy to see all of you. You got 3,000 people in this auditorium. There's 2,000 people in a courtyard watching us. There's another thousand people apparently in the fourth floor where there were supposed to be Nvidia show floors all watching this keynote and of course millions around the world are going to be watching this to kick off this new year.**
欢迎来到 CES。嗯，我们今天准备了大约 15 公斤重的内容要塞进这场演讲里。我非常高兴见到你们所有人。礼堂里坐了 3,000 人。院子里有 2,000 人在看着我们。显然在四楼——原本应该是 NVIDIA 展区的地方——还有另外一千人也在观看这场主题演讲，当然，全球还有数百万人将观看这场演讲，以此开启新的一年。

---

## 2. 计算机产业的范式转移

**Well, every 10 to 15 years the computer industry resets. A new platform shift happens from mainframe to PC, PC to internet, internet to cloud, cloud to mobile. Each time the world of applications target a new platform, that's why it's called a platform shift. You write new applications for a new computer.**
嗯，每隔 10 到 15 年，计算机产业就会重置一次。从大型机到 PC，从 PC 到互联网，从互联网到云，从云到移动端，新的平台转移就会发生。每一次，应用世界都会瞄准一个新平台，这就是为什么它被称为平台转移。你为一台新电脑编写新的应用程序。

**Except this time there are two simultaneous platform shifts in fact happening at the same time. While we now move to AI, applications are now going to be built on top of AI. At first people thought AIs are applications and in fact AIs are applications but you're going to build applications on top of AIs but in addition to that how you run the software how you develop the software fundamentally changed. The entire fabulary stack of the computer industry is being reinvented.**
除了一点，这一次事实上同时发生了两个平台转移。当我们现在向 AI 迈进时，应用程序现在将构建在 AI 之上。起初人们认为 AI 就是应用程序，事实上 AI 确实是应用程序，但你将在 AI 之上构建应用；除此之外，你如何运行软件、如何开发软件的方式也发生了根本性的变化。计算机产业的整个架构堆栈正处于重塑之中。

---

## 3. 计算方式的根本变革

**You no longer program the software, you train the software. You don't run it on CPUs, you run it on GPUs. And whereas applications were pre-recorded, pre-compiled and run on your device, now applications understand the context and generate every single pixel, every single token completely from scratch every single time.**
你不再对软件进行编程，而是训练软件。你不再在 CPU 上运行它，而是在 GPU 上运行。以前的应用程序是预先录制、预先编译并在你的设备上运行的，而现在的应用程序理解语境，并且每一次都完全从零开始生成每一个像素、每一个 Token。

**Computing has been fundamentally reshaped as a result of accelerated computing, as a result of artificial intelligence. Every single layer of that five layer cake is now being reinvented.**
由于加速计算和人工智能的结果，计算已被根本性地重塑。那个五层蛋糕（架构）的每一层现在都在被重新发明。

---

## 4. 行业现代化与资金流向

**Well, what that means is some 10 trillion dollars or so of the last decade of computing is now being modernized to this new way of doing computing. What that means is hundreds of billions of dollars, a couple hundred billion dollars in VC funding each year is going into modernizing and inventing this new world. And what it means is a hundred trillion dollars of industry, several percent of which is R&D budget is shifting over to artificial intelligence.**
嗯，这意味着过去十年约 10 万亿美元规模的计算设施，现在正被现代化为这种新的计算方式。这意味着每年有数千亿、甚至两三千亿美元的风险投资正投入到现代化和发明这个新世界中。这意味着一个 100 万亿美元规模的产业，其中几个百分点的研发预算正转向人工智能。

**People ask where is the money coming from? That's where the money is coming from. the modernization of IT to AI, the shifting of R&D budgets from classical methods to now artificial intelligence methods, enormous amounts of investments coming into this industry, which explains why we're so busy.**
人们问钱从哪里来？钱就是从那里来的。从传统 IT 向 AI 的现代化转型，研发预算从传统方法转向人工智能方法，海量投资涌入这个行业，这解释了为什么我们如此忙碌。

---

## 5. 2025 年：不可思议的一年

**And this last year was no difference. This last year was incredible. This last year, there's a slide coming. This is what happens when you don't practice. This is the first keynote of the year. I hope it's your first keynote of the year. Otherwise, you can you have been pretty pretty busy. It's our first keynote of the year. We're going to get the spiderwebs out. And so 2025 was an incredible year. It's just see it seemed like everything was happening all at the same time. And it in fact it probably was.**
去年也不例外。去年是不可思议的一年。去年——有一张幻灯片要出来了。这就是不练习的后果。这是今年的第一场主题演讲。我希望这也是你们今年的第一场主题演讲。否则，你们可能一直非常非常忙。这是我们今年的第一场演讲。我们要扫清陈旧的蛛丝马迹（进入状态）。所以 2025 年是不可思议的一年。看起来一切似乎都在同一时间发生。事实上可能确实如此。

**The first thing of course is scaling loss. In 2015, the first language model that I thought was really going to make a difference made a huge difference. It was called BERT. 2017, Transformers came. It wasn't until 5 years later, 2022, that chat GPT moment happened and it awakened the world to the possibilities of artificial intelligence.**
第一件事当然是缩放定律（Scaling Laws）。在 2015 年，第一个我认为真正会产生影响的语言模型产生了巨大的影响，它叫 BERT。2017 年，Transformers 问世。直到 5 年后的 2022 年，ChatGPT 时刻才发生，它让世界意识到人工智能的可能性。

**Something very important happened a year after that. The first o1 model from chat GPT the first reasoning model completely revolutionary invented this idea called test time scaling which is very common sens common sensical thing not only do we pre-train a model to learn, we post-train it with our reinforcement learning so that it could learn skills and now we also have test time scaling which is another way of saying thinking you think in real time each one of these phases of artificial intelligence requires enormous amount of comput and the computing law continued to scale.**
在那之后的一年，发生了一些非常重要的事情。来自 ChatGPT 的第一个 o1 模型，第一个推理模型，彻底革命性地发明了这个被称为“推理时缩放”（Test-time Scaling）的概念，这是一个非常符合常识的事情：我们不仅通过预训练让模型学习，还通过我们的强化学习对其进行后训练，使其能够学习技能；而现在我们还有了推理时缩放，这是“思考”的另一种说法——你进行实时思考。人工智能的每一个阶段都需要海量的计算，计算定律也在继续扩展。

---

## 6. 智能体系统 (Agentic Systems)

**Large language models continued to get better. Meanwhile, another breakthrough happened and this breakthrough happened in 2024. Agentic systems started to emerge in 2025. It started to pervase to to uh proliferate just about everywhere. Agentic models that have the ability to reason, look up information, do research, use tools, plan futures, simulate outcomes. All of a sudden started to solve very very important problems.**
大语言模型继续变得更好。与此同时，另一个突破发生了，这个突破发生在 2024 年。智能体系统在 2025 年开始涌现。它开始渗透、呃、在几乎所有地方激增。智能体模型具有推理、查找信息、做研究、使用工具、规划未来、模拟结果的能力。突然之间，它们开始解决非常非常重要的问题。

**One of my favorite Agentic models is called cursor which revolutionized the way we do software programming at NVIDIA. Agentic systems are going to really take off from here.**
我最喜欢的智能体模型之一叫 Cursor，它彻底改变了我们在 NVIDIA 进行软件编程的方式。智能体系统将从这里真正起飞。

---

## 7. 物理 AI 与 AI 物理学

**Of course, there were other types of AI. We know that large language models isn't the only type of information. Wherever the universe has information, wherever the universe has structure, we could teach a large language model a form of language model to go understand that information to understand its representation and to turn that into an AI. One of the biggest most important one is physical AI. AIs that understand the laws of nature.**
当然，还有其他类型的 AI。我们知道大语言模型不是信息的唯一类型。宇宙中任何有信息、有结构的地方，我们都可以教大语言模型（一种语言模型形式）去理解那些信息，理解其表达方式并将其转化为 AI。其中最大、最重要的一种是物理 AI，即理解自然法则的 AI。

**And then of course physical AI is about AIs interacting with the world but the world itself has information encoded information and that's called AI physics. AI that in the case of physical AI you have AI that interacts with the physical world and you have AI physics AI that understands the laws of physics.**
当然，物理 AI 是关于 AI 与世界的互动，但世界本身包含着编码信息，这被称为 AI 物理学。在物理 AI 的情况下，你有与物理世界互动的 AI，以及理解物理定律的 AI 物理学。

---

## 8. 开源模型的革命：DeepSeek R1

**And lastly one of the most important things that happened last year the advancement of open models. We can now know that AI is going to proliferate everywhere when open source when open innovation when innovation across every single company and every industry around the world is activated. At the same time, open models really took off last year. In fact, last year we saw the advance of DeepSeek R1, the first open model that's a reasoning system. It caught the world by surprise and it activated literally this entire movement. Really, really exciting work. We're so happy with it.**
最后，去年发生的最重要的事情之一是开源模型的进步。我们现在知道，当开源、开放创新、以及全球每个公司和每个行业的创新被激活时，AI 将无处不在。与此同时，开源模型去年真正起飞了。事实上，去年我们见证了 DeepSeek R1 的进步，这是第一个具备推理能力的开源模型。它让世界大吃一惊，并且毫不夸张地激活了整个运动。非常非常令人兴奋的工作。我们对此感到非常高兴。

**Now we have openings open model systems all over the world of all different kinds and we now know that open models have also reached the frontier. still solidly is six months behind the frontier models but every single six months a new model is emerging and these models are getting smarter and smarter because of that you could see the number of downloads has exploded the number of downloads is growing so fast because startups want to participate in the AI revolution large companies want to researchers want to students want to just about every single country wants.**
现在我们在世界各地拥有各种类型的开放模型系统，我们现在知道开放模型也已经达到了前沿。虽然它们仍稳稳地落后于前沿模型六个月，但每隔六个月就会有一个新模型出现，这些模型变得越来越聪明。因此，你可以看到下载量呈爆炸式增长，下载量增长得如此之快，是因为初创公司想要参与 AI 革命，大公司想要参与，研究人员想要参与，学生想要参与，几乎每一个国家都想要参与。

**How is it possible that intelligence, the digital form of intelligence will leave anyone behind and so open models has really revolutionized artificial intelligence last year. This entire industry is going to be reshaped as a result of that.**
智能——这种数字形式的智能——怎么可能把任何人留在身后呢？所以开源模型在去年真正彻底改变了人工智能。整个行业都将因此而被重塑。

---

## 9. NVIDIA 的 DGX Cloud 与模型开发

**Now, we had this inkling some time ago. You might have heard that several years ago, we started to build and operate our own AI supercomputers. We call them DGX clouds. A lot of people asked, are you going to in going into the cloud business? The answer is no. We're building these DGX supercomputers for our own use. Well, it turns out we have billions of dollars of supercomputers in operation so that we could develop our open models. I am so pleased with the work that we're doing.**
我们在一段时间前就有了这种预感。你们可能听说过，几年前，我们开始建立并运行我们自己的 AI 超级计算机。我们称之为 DGX Cloud。很多人问，你们是要进军云业务吗？答案是否定的。我们建造这些 DGX 超级计算机是为了自用。事实证明，我们有价值数十亿美元的超级计算机在运行，以便我们开发我们的开放模型。我对我们正在做的工作感到非常欣慰。

**It is starting to attract attention all over the world and all over the industries because we are doing frontier AI model work in so many different domains. the work that we did in proteins in digital biology. La Protina to be able to synthesize and generate proteins. Open F3 (OpenFold) to understand the understand the structure of proteins. EVO 2 how to understand and generate multiple proteins otherwise the beginnings of cellular cellular representation. Earth 2 AI that understands laws of physics.**
它正开始吸引全世界和各行各业的关注，因为我们在这么多不同的领域进行前沿 AI 模型的研究。我们在数字生物学蛋白质方面的工作，La Protina 能够合成并生成蛋白质。Open Fold 用于理解蛋白质结构。EVO 2 用于理解并生成多种蛋白质，换句话说，它是细胞表征的开始。Earth-2 是理解物理定律的 AI。

**The work that we did with forecast net, the work that we did with Cordiff really revolutionized the way that people are doing weather prediction. Neotron, we've now doing groundbreaking work there. The first hybrid transformer SSM model that's incredibly fast can and therefore can think for a very long time or can think very quickly with that for not a very long time and produce very very smart intelligent answers. Neimotron 3 is groundbreaking work and you can expect us to deliver other versions of Neimotron 3 in the near future.**
我们在 ForecastNet 上的工作，我们在 CorrDiff 上的工作，真正彻底改变了人们进行天气预报的方式。Nemotron，我们现在在那里做着开创性的工作。第一个混合 Transformer-SSM 模型，速度快得惊人，因此可以思考很长时间，或者以此极快地思考并不太长的时间，并产生非常非常聪明的智能回答。Nemotron-3 是开创性的工作，你可以期待我们在不久的将来交付 Nemotron-3 的其他版本。

---

## 10. Cosmos、GR00T 与 Alpamo (自动驾驶)

**Cosmos a frontier open world foundation model one that understand how the world works. Groot a humanoid robotic system articulation mobility locomotion. These models, these technologies are now being integrated and in the each one of these cases open to the world. Frontier human or robotics models open to the world.**
Cosmos，一个前沿的开放世界基础模型，一个理解世界运作方式的模型。GR00T，一个人形机器人系统，负责关节连接、移动和行走。这些模型、这些技术现在正被集成，并且在每一个案例中都对世界开放。前沿的人形机器人模型对世界开放。

**And then today we're going to talk a little bit about Alpamo, the work that we've been doing in self-driving cars. Not only do we open source the models, we also open source the data that we use to train those models because that in that way only in that way can you truly trust how the models came to be. We open source all the models. We help you make derivatives from them.**
然后今天我们要谈谈 Alpamo，我们在自动驾驶汽车方面所做的工作。我们不仅开源了模型，还开源了我们用来训练这些模型的数据，因为只有那样，也唯有通过那样的方式，你才能真正信任这些模型是如何诞生的。我们开源了所有模型。我们帮助你基于它们开发衍生产品。

**We have a whole suite of libraries we call the Nemo libraries, physics nemo libraries and the clarono libraries. Each biono libraries each one of these libraries are life cycle management systems of AIS so that you could process the data you could generate data you could train the model you could create the model evaluate the model guardrail the model all the way to deploying the model each one of these libraries are incredibly complex and all of it is open sourced.**
我们有一整套库，我们称之为 Nemo 库、物理 Nemo 库和 Clarono 库。每一个 Biono 库，这些库中的每一个都是 AI 的生命周期管理系统，这样你就可以处理数据、生成数据、训练模型、创建模型、评估模型、为模型设置护栏，直到部署模型，这些库中的每一个都极其复杂，而且全部都是开源的。

---

## 11. NVIDIA 作为前沿模型构建者

**And so now on top of this platform NVIDIA is a frontier AI model builder and we build it in a very special way. We build it completely in the open so that we can enable every company, every industry, every country to be part of this AI revolution. I'm incredibly proud of the work that we're doing there. In fact, if you notice the tren the charts, the chart shows that our contribution to this industry is bar none and you're going to see us in fact continue to do that if not accelerate.**
所以现在，在这个平台之上，NVIDIA 是一家前沿 AI 模型构建者，我们以一种非常特殊的方式进行构建。我们完全以开放的方式构建它，以便我们能够让每个公司、每个行业、每个国家都成为这场 AI 革命的一部分。我为我们在那里所做的工作感到无比自豪。事实上，如果你注意到那些图表，图表显示我们对这个行业的贡献是无与伦比的，而你将会看到我们实际上会继续这样做，甚至会加速。

---

## 12. 现场花絮：系统故障与即兴发挥

**These models are also world class. All systems are down. Is it because of Las Vegas? Somebody must have went won a jackpot outside. All systems are down. Okay, I think my system's still down, but that's okay. I I I've I uh I'll make it up as I go.**
这些模型也是世界级的。所有系统都停机了。是因为在拉斯维加斯吗？肯定有人在外面中了头奖。所有系统都停机了。好吧，我想我的系统还挂着，但没关系。我会边走边即兴发挥。

---

## 13. 排行榜榜首与多模态能力

**And so so uh not only are these models uh frontier capable, not only are they open, they're also top the leaderboards. This is an area where we're very proud. They top leaderboards in intelligence. Uh we have uh uh important models that understand multimodality documents, otherwise known as PDFs. The most valuable content in the world are captured in PDFs. But there it takes artificial intelligence to find out what's inside, interpret what's inside, and help you read it. And so our PDF retrievers, our PDF parsers are worldclass.**
所以，不仅这些模型具有前沿能力，不仅它们是开放的，它们还荣登排行榜榜首。这是我们非常自豪的一个领域。它们在智能排行榜上名列前茅。我们有一些理解多模态文档（也就是 PDF）的重要模型。世界上最有价值的内容都捕捉在 PDF 中。但需要人工智能来发现其中的内容，解释其中的内容，并帮助你阅读它。所以我们的 PDF 检索器、我们的 PDF 解析器都是世界级的。

**Our speech recognition models absolutely worldclass. Our retrieval models, basically search, semantic search, AI search, the database engine of the modern AI era, worldclass. So we're on top of leaderboards constantly. This is an area we're very proud of and all of that is in service of your ability to build AI agents. This is really a groundbreaking area of development.**
我们的语音识别模型绝对是世界级的。我们的检索模型，基本上就是搜索、语义搜索、AI 搜索，现代 AI 时代的数据库引擎，也是世界级的。所以我们一直处于排行榜的前列。这是我们非常自豪的一个领域，而所有这一切都是为了服务于你构建 AI 智能体的能力。这确实是一个开创性的发展领域。

---

## 14. 推理：从幻觉到逻辑

**You know at first when pe when chat GPT came out people said you know uh gosh it it produced really interesting results but it hallucinated greatly. And the reason why it hallucinated, of course, it could memorize everything um in the past, but it can't memorize everything in the future, in the current. And so it needs to be grounded in research. It has to do fundamental research before it answers a question.**
你知道，起初 ChatGPT 问世时，人们说，天哪，它产生了非常有趣的结果，但它幻觉很严重。它产生幻觉的原因，当然是它能记住过去的一切，但它记不住未来、记不住当前的一切。所以它需要立足于研究。在回答问题之前，它必须进行基础研究。

**The ability to reason about do I have to do research? Do I have to use tools? How do I break up a problem into steps? Each one of these steps something that that the AI model knows how to do. And together it is able to compose it into a sequence of steps to perform something it's never done before, never been trained to do. This is the wonderful capability of reasoning.**
这种推理能力包括：我需要做研究吗？我需要使用工具吗？我如何将问题分解为步骤？每一个步骤都是 AI 模型知道如何去做的事情。结合在一起，它能够将其组合成一系列步骤，去执行一些它以前从未做过、从未被训练去做的事情。这就是推理的奇妙能力。

**We could we could be we can encounter a circumstance we've never seen before and break it down into circumstances and knowledge or rules that we know how to do because we've experienced it in the past. And so the ability for AI models now to be able to reason incredibly powerful. The reasoning capability of agents opened the doors to all of these different applications.**
我们可以遇到以前从未见过的环境，并将其分解为我们知道如何处理的环境、知识或规则，因为我们过去经历过。所以 AI 模型现在的推理能力极其强大。智能体的推理能力为所有这些不同的应用打开了大门。

---

## 15. 强化学习与 Perplexity 的启发

**We no longer have to train an AI model to know everything on day one. Just as we don't have to know everything on day one, that we should be able to in every circumstance reason about how to solve that problem. Large language models has now made this fundamental leap. The ability to use reinforcement learning and chain of thought and you know search and planning and all these different techniques in reinforcement learning has made it possible for us to have this basic capability and is also now completely open sourced.**
我们不再需要训练一个 AI 模型在第一天就掌握一切。就像我们不需要在第一天就了解一切一样，我们应该能够在任何情况下推理出如何解决那个问题。大语言模型现在已经实现了这一根本性的飞跃。利用强化学习、思维链以及你知道的搜索和规划，以及强化学习中所有这些不同的技术，使我们能够拥有这种基本能力，而且现在已经完全开源。

**But the thing that's really terrific is another breakthrough that happened and the first time I saw it was with Arvin's perplexity. Perplexity, the search company, the AI search company, really f really innovative company. And the first time I realized they were using multiple models at the same time, I thought it was completely genius. Of course, we would do that. Of course, an AI would also call upon all of the world's great AIs to solve the problem it wants to solve at any part of the reasoning chain.**
但真正了不起的是发生的另一个突破，我第一次看到它是在 Arvin 的 Perplexity。Perplexity，那家搜索公司，那家 AI 搜索公司，真的是一家非常创新的公司。当我第一次意识到他们同时使用多个模型时，我觉得这完全是天才之举。当然，我们会那样做。当然，一个 AI 也会调用世界上所有伟大的 AI，在推理链的任何部分解决它想要解决的问题。

---

## 16. 多模态、多模型与混合云

**And this is the reason why AIs are really multi-modal meaning they understand speech and images and text and videos and 3D graphics and proteins. It's multimodal. It's also multi-model meaning that it should be able to use any model that best fits the task. It is multicloud by definition. Therefore, because these AI models are sitting in all these different places and it also is hybrid cloud because if you're an enterprise company or you've built a robot or whatever that device is, sometimes it's at the edge, sometimes a radio cell tower, maybe sometimes it's in an enterprise or maybe it's a place where a hospital where you need to have the the data in real time right next to you. Whatever those applications are, we know now this is what an AI application looks like in the future.**
这就是为什么 AI 真正是“多模态”的——意味着它们理解语音、图像、文本、视频、3D 图形和蛋白质。它是多模态的。它也是“多模型”的——意味着它应该能够使用任何最适合该任务的模型。从定义上讲，它是多云的。因此，因为这些 AI 模型位于所有这些不同的地方，而且它也是混合云，因为如果你是一家企业公司，或者你制造了一个机器人，或者无论那个设备是什么，有时它在边缘，有时在无线电信号塔，也许有时它在企业内部，或者也许是在医院，你需要数据就在你身边实时处理。无论这些应用是什么，我们现在知道未来的 AI 应用就是这个样子的。

**Or another way to think about that because future applications are built on AIS. This is the basic framework of future applications. This basic framework, this basic structure of agentic AIs that could do the things that I'm talking about that is multi-model has now turbocharged AI startups of all kinds.**
或者换一种思考方式，因为未来的应用是建立在 AI 之上的。这就是未来应用的基本框架。这个基本框架，这个具备我所说的能力的智能体 AI 的基本结构，即多模型架构，现在已经为各种 AI 初创公司提供了动力。

---

## 17. 定制化 AI 与智能路由

**And now you can also because of the all of the open models and all the tools that we provided you, you could also customize your AIs to teach your AI skills that nobody else is teaching. Nobody else is causing their AI to become intelligent or smart in that way. You could do it for yourself. And that's the work that we do with Neimotron, Nemo, and all of the things that we do with open models is intended to do. You put a smart router in front of it. And that router is essentially a manager that decides which one of the task based on the intention of the prompts that you give it, which one of the models is best fit for that application for that solving that problem.**
现在你也可以，由于我们提供给你的所有开放模型和所有工具，你也可以定制你的 AI，教你的 AI 别人没有教过的技能。没有其他人会让他们的 AI 以那种方式变得智慧或聪明。你可以为自己做到这一点。这就是我们通过 Nemotron、Nemo 以及我们对开源模型所做的一切工作旨在实现的。你在它前面放一个智能路由。那个路由本质上是一个管理者，它根据你给它的提示词意图，决定哪一个模型最适合该应用、最适合解决那个问题。

---

## 18. 企业蓝图架构

**Okay. So now when you think about this architecture, what do you have? When you think about this architecture, all of a sudden you have an AI that's on the one hand completely customizable by you. Something that you could teach to do your own very skills for your company. Something that's domain secret, something where you have deep domain expertise. Maybe you've got all of the data that you need to train that AI model. On the other hand, your AI is always at the frontier by definition. You're always at the frontier. On the one hand, you're always customized. On the other hand, it should just run.**
好。所以现在当你思考这个架构时，你拥有了什么？当你思考这个架构时，突然之间你拥有了一个 AI，一方面它完全可以由你定制。你可以教它为你的公司做你特有的技能。一些领域秘密，一些你拥有深厚领域专业知识的东西。也许你拥有训练那个 AI 模型所需的所有数据。另一方面，根据定义，你的 AI 始终处于前沿。你始终处于前沿。一方面，你始终是定制化的。另一方面，它应该能直接运行。

**And so, we thought we would make the simplest of examples to make it available to you. This entire framework we call a blueprint and we have blueprints that are integrated into enterprise SAS platforms all over the world and we're really pleased with the progress. But what we do is show you a a short example of something that anybody can do. Let's build a personal assistant.**
所以，我们想做一个最简单的例子来展示给你们。我们将整个框架称为“蓝图”，我们有已经集成到全球企业级 SaaS 平台中的蓝图，我们对这一进展感到非常高兴。但我们要向你展示的是一个任何人都能做的简短示例。让我们来构建一个个人助理。

---

## 19. 个人助理演示 (DGX Spark + Reachi 机器人)

**I wanted to help me with my calendar, emails, to-do lists, and even keep an eye on my home. I use Brev to turn my DGX Spark into a personal cloud. So, I can use the same interface whether I'm using a cloud GPU or a DGX Spark. I use a Frontier model API to easily get started. I want him to help me with my emails, so I create an email tool for my agent to call. I want my emails to stay private, so I'll add an open model that's running locally on the Spark.**
我想让它帮我处理日历、邮件、待办事项列表，甚至帮我照看家。我使用 Brev 将我的 DGX Spark 变成个人云。这样，无论我使用的是云端 GPU 还是 DGX Spark，我都可以使用相同的界面。我使用前沿模型的 API 来轻松开始。我想让它帮我处理电子邮件，所以我为我的智能体创建了一个电子邮件工具供其调用。我希望我的邮件保持私密，所以我将添加一个在 Spark 本地运行的开放模型。

**Now, for any job, I want the agent to use the right model for the right task. So, I'll use an intentbased model router. This way, prompts that need email will stay on my Spark, and everything else can call the Frontier model. I want my assistant to interact with my world, so I'll hook it up to Hugging Faces Reachi mini robot. My agent controls the head, ears, and camera of the Reachi with tool calls. I want to give Reichi a voice, and I really like 11 Labs, so I'll hook up their API.**
现在，对于任何工作，我都希望智能体为正确的任务使用正确的模型。所以，我将使用一个基于意图的模型路由。这样，需要处理邮件的提示词将留在我的 Spark 上，其他所有内容都可以调用前沿模型。我希望我的助手能与我的世界互动，所以我把它连接到 Hugging Face 的 Reachi 迷你机器人上。我的智能体通过工具调用来控制 Reachi 的头部、耳朵和摄像头。我想给 Reichi 一个声音，我很喜欢 11 Labs，所以我连接了他们的 API。

**Hi, I'm Reachi running on DGX Spark.**
嗨，我是运行在 DGX Spark 上的 Reachi。

**Hey Richi, what's on my to-do list today? your to-do list today. Grab groceries, eggs, milk, butter, and send Jensen the new script.**
嘿 Reachi，我今天的待办事项有什么？你今天的待办事项是：买杂货，鸡蛋、牛奶、黄油，还有给 Jensen 发送新剧本。

**Okay, let's send Jensen an update. Tell him we'll have it for him by the end of the day. We'll do.**
好的，给 Jensen 发一个更新。告诉他我们会在今天结束前交给他。好的。

**Richi, there's a sketch, too. Can you turn it into an architectural rendering? Sure. Nice. Now make a video and show me around the room. Here you go.**
Reachi，还有一个草图。你能把它变成建筑渲染图吗？当然。太棒了。现在做一个视频，带我看看房间周围。给你。

**That's great. With Brev, I can share access to my Spark and Reachi, so I'm going to share it with Anna. Hey Richi, what's Potato up to? He's on the couch. I remember you don't like this. I'll tell him to get off. Potato, off the couch. With all the progress in open source, it's incredible to see what you can build. I'd love to see what you create.**
太棒了。通过 Brev，我可以分享我的 Spark 和 Reachi 的访问权限，所以我要把它分享给 Anna。嘿 Reachi，“小土豆”（Potato，宠物名）在做什么？它在沙发上。我记得你不喜欢这样。我会告诉它下去。土豆，离开沙发。随着开源的所有进展，看到你能构建出什么真是不可思议。我很想看看你们创造了什么。

---

## 20. 现代应用的架构

**Isn't that incredible? Now, the amazing thing is that is utterly trivial now. That is utterly trivial now. And yet, just a couple years ago, all of that would have been impossible. Absolutely unimaginable. Well, this basic framework, this basic way of building applications using language models using language models. Using language models using language models that are pre-trained and they're proprietary, they're frontier. combine it with customized language models into a aentic framework, a reasoning framework that allows you to access tools and files and maybe even connect to other agents. This is basically the architecture of AI applications or applications in the modern age and the ability for us to create these applications are incredibly fast.**
这难道不神奇吗？现在，令人惊讶的是，这现在已经是再平常不过的事了。现在这简直是微不足道的事情。然而，就在几年前，这一切都是不可能的。绝对无法想象。嗯，这个基本框架，这种使用语言模型构建应用程序的基本方式——使用语言模型。使用预训练的、专有的、前沿的语言模型。将其与定制的语言模型结合到一个智能体框架中，一个推理框架中，允许你访问工具、文件，甚至可能连接到其他智能体。这基本上就是 AI 应用或现代应用架构，我们创建这些应用的能力极其迅速。

**And notice if you give it this application um information that it's never seen before or in a structure that has is not represented exactly as you thought it can still reason through it and make its best effort to reason through the data the information to try to understand how to solve the problem artificial intelligence.**
注意，如果你给这个应用一些它从未见过的信息，或者其结构与你想象的并不完全一致，它仍然可以通过它进行推理，并尽最大努力通过数据和信息进行推理，尝试理解如何解决人工智能问题。

---

## 21. 企业合作伙伴与 UI 的革命

**Okay. So this basic framework is now being integrated and and everything that I just described. We had the benefit of working with some of the world's leading enterprise platform companies. Uh Palunteer for example um their their entire AI and data processing platform is being integrated accelerated by NVIDIA today. Service Now the world's leading customer service and um employee service platform. Snowflake the world's top data platform in the cloud. uh incredible work that that uh is being done there. Code Rabbit, we're using Code Rabbit all over Nvidia. Uh Crowdstrike creating AIs to detect to find AI threats. Uh NetApp, their AI, their data platform now has NVIDIA's semantic AI on top of it and agentic systems on top of it uh uh to for uh for them to do customer service.**
好。所以这个基本框架现在正被集成到，以及我刚才描述的所有内容。我们有幸与一些世界领先的企业平台公司合作。例如 Palantir，嗯，他们的整个 AI 和数据处理平台今天正在被 NVIDIA 加速集成。ServiceNow，世界领先的客户服务和员工服务平台。Snowflake，世界顶级的云端数据平台。那里正在进行不可思议的工作。Code Rabbit，我们在 NVIDIA 各处都在使用 Code Rabbit。CrowdStrike 正在创建 AI 来检测、发现 AI 威胁。NetApp，他们的 AI 和数据平台现在顶层拥有 NVIDIA 的语义 AI 和智能体系统，用于他们提供客户服务。

**But the important thing is this. Not only is this the way that you develop applications now, this is going to be the user interface of your platform. So whether it's Palanteer or Service Now or Snowflake and many other companies that we're working with, the agentic system is the interface. It's no longer Excel with a bunch of, you know, squares that you enter enter information into. Maybe it's no longer could just command line. the any all of that multimodality information is now possible and the way you interact with your platform is much more well if you will simple like you're interacting with people and so that's enterprise AI being revolutionized by angentic systems.**
但重要的事情是：这不仅是现在开发应用方式，这还将成为你平台的“用户界面”。所以无论是 Palantir、ServiceNow 还是 Snowflake 以及许多其他我们正在合作的公司，智能体系统就是界面。它不再是那种带有一堆输入信息的方格的 Excel。也许它不再仅仅是命令行。任何所有的多模态信息现在都是可能的，你与平台交互的方式变得更加——如果你愿意的话——就像你与人交互一样简单。所以这就是企业级 AI 正在被智能体系统彻底改变。

---

## 22. 物理 AI 的常识挑战

**The next thing is physical AI this is an area that you've seen me talk about for several years in fact we've been working on this for eight years the question is how do you take something that is intelligent inside a computer and interacts with you with screens and speakers to something that can interact with the world. Meaning it can understand the common sense of how the world works. Object permanence. If I look away and I look back, that object is still there. Um causality. If I push it, it tips over. It understands friction and gravity. It understands inertia. that a heavy truck rolling down the road is going to need a little bit more time to stop, that a ball is going to keep on rolling.**
下一件事是物理 AI，这是一个你们已经听我谈论了好几年的领域，事实上我们已经为此工作了八年。问题是，你如何将计算机内部的智能（通过屏幕和扬声器与你互动的东西）转化为能够与世界互动的智能。这意味着它能理解世界运作的常识。物体恒存性：如果我转过头再看回来，那个物体还在那里。因果关系：如果我推它，它会翻倒。它理解摩擦力和重力。它理解惯性：一辆在路上行驶的重型卡车需要更多时间停下来，而一个球会继续滚动。

**These ideas are common sense to even a little child, but for AI, it's completely unknown. And so we have to create a system that allows AIS to learn the the common sense of the physical world, learn its laws, but also to be able to of course learn from data and the data is quite scarce and to be able to evaluate whether that AI is working, meaning it has to simulate in an environment. How does an AI know that the the actions that it's performing is consistent with what it should do if it doesn't have the ability to simulate the response of the physical world back on its actions. The response of its actions is really important to simulate otherwise there's no way to evaluate it. It's different every time.**
这些想法甚至对一个小孩子来说都是常识，但对于 AI 来说，这完全是未知的。所以我们必须创建一个系统，让 AI 学习物理世界的常识，学习它的规律，同时当然也要能从数据中学习——而这类数据相当稀缺——并且要能够评估那个 AI 是否在工作，这意味着它必须在一个环境中进行模拟。如果 AI 没有能力模拟物理世界对其动作的反应，它怎么知道它执行的动作是否与它应该做的保持一致呢？动作的反馈模拟非常重要，否则根本无法评估。每一次都是不同的。

---

## 23. 三台计算机架构

**And so this basic system requires three computers. One computer of course the one that we know that Nvidia builds for training the AI models. Another computer that we know is to inference the computer. Inference the models. Inferencing the model is essentially a robotics computer that runs in a car or runs in a robot or runs in a factory, runs anywhere at the edge. But there has to be another computer that's designed for simulation and simulation is at the heart of almost everything Nvidia does. This is this is where we are most comfortable and simulation was really the foundations of almost everything that we've done with physical AI.**
所以这个基础系统需要三台计算机。一台计算机当然是我们知道的 NVIDIA 建造的用于训练 AI 模型的计算机。另一台计算机是我们所知的推理计算机，推理模型。推理模型本质上是一台机器人计算机，运行在汽车里、机器人里或工厂里，运行在边缘的任何地方。但还必须有另一台专门为模拟而设计的计算机，模拟几乎是 NVIDIA 所做一切的核心。这是我们最擅长的领域，模拟确实是我们处理物理 AI 所做的一切的基础。

**So we have three computers and multiple stacks that run on these computers, these libraries to make them useful. Omniverse is our digital twin physically based simulation world. Cosmos as I mentioned earlier is our foundation model not a foundation model for language but a foundation model of the world. and is also aligned with language. You could say something like, you know, what's happening to the ball and they they'll tell you the ball's rolling down the street. And so a world foundation model and then of course the robotics models. We have two of them. One of them is called Groot. The other one's called Alpamo that I'm going to tell you about.**
所以我们有三台计算机，以及运行在这些计算机上的多个堆栈、这些库，使它们发挥作用。Omniverse 是我们的数字孪生、基于物理的模拟世界。正如我之前提到的，Cosmos 是我们的基础模型，不是语言基础模型，而是“世界基础模型”。它也与语言对齐。你可以说类似，“你知道，那个球怎么了？”它们会告诉你球正滚下街道。所以是一个世界基础模型，然后当然还有机器人模型。我们有两个，一个叫 GR00T，另一个叫 Alpamo，我待会会告诉你们。

---

## 24. 物理 AI 数据与合成生成

**Now the one of the most important things that we have to do with physical AI is to create the data to train the AI in the first place. Where does that data come from? rather than instead of having languages because we created a bunch of text that are what we consider ground truth that the AI can learn from. How do we teach an AI the ground truth of physics? There lots and lots of videos, lots and lots of videos, but hardly enough to capture the diversity and the type of interactions that we need. And so this is where great minds came together and transformed what used to be compute into data.**
现在，对于物理 AI 我们必须做的最重要的事情之一，首先是创建用于训练 AI 的数据。那些数据从哪里来？不像语言那样，我们可以创建一堆我们认为是“地面真值”（ground truth）的文本让 AI 学习。我们如何教 AI 物理学的真值？虽然有很多很多视频，但还远远不足以捕捉我们需要的多样性和互动类型。所以这就是伟大的思想聚集在一起，将曾经的“计算”转化为“数据”的地方。

**Now using synthetic data generation that is grounded and conditioned by the laws of physics, grounded and conditioned by ground truth, we can now selectively cleverly generate data that we can then use to train the AI. So for example, what comes into this AI, this Cosmos AI world model on the left on over here is the output of a traffic simulator. Now this traffic simulator is hardly enough for an AI to learn from. We can take this, put it into a Cosmos foundation model and generate surround video that is physically based and physically plausible that the AI can now learn from. And there are so many examples of this. Let me show you what Cosmos can do.**
现在通过使用以物理定律为基础和条件的合成数据生成，以地面真值为基础和条件的合成数据生成，我们现在可以有选择地、巧妙地生成数据，然后我们可以用这些数据来训练 AI。所以举例来说，进入左边这个 Cosmos AI 世界模型的是交通模拟器的输出。现在，这个交通模拟器对于 AI 的学习来说还远远不够。我们可以把这个输入 Cosmos 基础模型，并生成基于物理、且物理逻辑合理的环绕视频，供 AI 学习。这样的例子有很多。让我向你展示 Cosmos 能做什么。

---

## 25. Cosmos 基础模型介绍 (视频解说词)

**The chat GPT moment for physical AI is nearly here, but the challenge is clear. The physical world is diverse and unpredictable. Collecting real world training data is slow and costly and it's never enough. The answer is synthetic data. It starts with NVIDIA Cosmos, an open Frontier World Foundation model for physical AI pre-trained on internet scale video, real driving and robotics data, and 3D simulation.**
物理 AI 的 ChatGPT 时刻即将到来，但挑战是显而易见的。物理世界多样且不可预测。收集现实世界的训练数据缓慢且昂贵，而且永远不够。答案是合成数据。它始于 NVIDIA Cosmos，这是一个为物理 AI 打造的开放前沿世界基础模型，预训练于互联网规模的视频、真实的驾驶和机器人数据，以及 3D 模拟。

**Cosmos learned a unified representation of the world, able to align language, images, 3D, and action. It performs physical AI skills like generation, reasoning, and trajectory prediction from a single image. Cosmos generates realistic video from 3D scene descriptions, physically coherent motion, from driving telemetry and sensor logs, surround video from planning simulators, multi- camera environments, or from scenario prompts. It brings edge cases to life. Developers can run interactive closed loop simulations in Cosmos. When actions are made, the world responds. Cosmos reasons. It analyzes edge scenarios, breaks them down into familiar physical interactions, and reasons about what could happen next. Cosmos turns compute into data, training AVs for the longtail and robots how to adapt for every scenario.**
Cosmos 学习了世界的统一表征，能够对齐语言、图像、3D 和动作。它能从一张图片中执行物理 AI 技能，如生成、推理和轨迹预测。Cosmos 能根据 3D 场景描述生成写实视频，根据驾驶遥测和传感器日志生成物理连贯的动作，根据规划模拟器生成环绕视频，在多摄像头环境下或根据场景提示词工作。它让边缘案例栩栩如生。开发者可以在 Cosmos 中运行交互式闭环模拟。当做出动作时，世界会做出回应。Cosmos 会推理。它分析边缘场景，将其分解为熟悉的物理交互，并推理接下来可能发生的事情。Cosmos 将计算转化为数据，训练自动驾驶应对长尾效应，并训练机器人如何适应每一种场景。

---

## 26. Alpamo：首款能推理的自动驾驶 AI

**I know it's incredible. Cosmos is the world's leading foundation model. World foundation model. It's been downloaded millions of times, used all over the world, getting world getting the world ready for this new era of physical AI. We use it ourselves as well. We use it ourselves to create our self-driving car. using it for scenario generation and using it for evaluation. We could have something that allows us to effectively travel billions, trillions of miles, but doing it inside a computer. And we've made enormous progress.**
我知道这很不可思议。Cosmos 是世界领先的基础模型。世界基础模型。它已经被下载了数百万次，在全球各地被使用，让世界为这个物理 AI 的新时代做好准备。我们自己也在使用它。我们用它来创造我们的自动驾驶汽车。用它进行场景生成，并用它进行评估。我们可以拥有一种能够让我们有效地“行驶”数十亿、数万亿英里的方式，但在计算机内部完成。我们已经取得了巨大的进步。

**Today, we're announcing Alpamo, the world's first thinking reasoning autonomous vehicle AI. Alpamo is trained end to end. Literally from camera in to actuation out. The camera in lots and lots of miles that are driven by itself where we human drive it dri using human demonstration and we have lots and lots of miles that are generated by cosmos.**
今天，我们宣布 Alpamo，世界上第一个能够思考和推理的自动驾驶汽车 AI。Alpamo 是端到端训练的。字面上是从摄像头输入到执行输出。摄像头输入的许多英里是由其自动驾驶的，或者是我们人类通过人类演示驾驶的，我们还有由 Cosmos 生成的很多很多英里的数据。

**In addition to that, hundreds of thousands of examples are labeled very very carefully so that we could teach the car how to drive. Alpamo does something that's really special. Not only does it take sensor input and activates steering wheel, brakes and and acceleration, it also reasons about what action it is about to take. It tells you what action it's going to take. the reasons by which it came about that action and then of course the trajectory.**
除此之外，成千上万个示例被非常非常仔细地标注，以便我们可以教汽车如何驾驶。Alpamo 做到了一些非常特别的事情。它不仅接收传感器输入并激活方向盘、刹车和油门，它还推理它即将采取的动作。它告诉你它将采取什么动作，它产生那个动作的原因，当然还有轨迹。

**All of these are coupled directly and trained very specifically by a large combination of human trained and as well as Cosmos generated data. The result of it is just really incredible. Not only does your car drive as you would expect it to drive and it drives so naturally because it learned directly from human demonstrators but in every single scenario when it comes up to the scenario it reasons about it tells you what it's going to do and it reasons about what you what's about to do.**
所有这些都直接耦合在一起，并通过大量人工训练数据和 Cosmos 生成数据的结合进行了非常具体的训练。其结果真的令人难以置信。不仅你的车开起来就像你期望的那样，而且开得非常自然，因为它直接从人类演示者那里学习；而且在每一个场景中，当它遇到该场景时，它会进行推理，告诉它要做什么，并推理它即将要做什么。

---

## 27. 应对长尾效应与实时路测演示

**Now the reason why this is so important is because of the long tale of driving there. It's impossible for us to simply collect every single possible scenario for everything that could ever happen in every single country in every single circumstance that's possibly ever going to happen for all of population. However, it is very unlikely. It's very likely that every scenario if decomposed into a whole bunch of other smaller scenarios are quite normal for you to understand. And so these long tails will be decomposed into quite normal circumstances that the card knows how to deal with. It just needs to reason about it.**
现在，这之所以如此重要的原因是因为驾驶的长尾效应。我们不可能简单地为每个国家、每种情况下可能发生的每种可能场景收集数据。然而，这不太可能发生。但很有可能每一个场景，如果分解成一堆其他较小的场景，对你来说都是很平常且易于理解的。因此，这些长尾场景将被分解为相当普通的情况，车辆知道如何处理。它只需要进行推理。

**And so let's take a look. Everything you're about to see is one shot. It's a no hands.**
让我们来看一下。你即将看到的一切都是一次性拍摄的。这是全程脱手的。

**Routing to your destination. Buckle up. Heat. Heat. Heat. Heat. Heat. Heat. Heat. Heat. Heat. Heat. Heat. Heat. You have arrived.**
正在规划前往目的地的路线。请系好安全带。（视频提示音：热。热。热。热...）你已到达。

---

## 28. 全栈努力与梅赛德斯合作伙伴关系

**We started working on self-driving cars eight years ago. And the reason for that is because we reason early on that deep learning and artificial intelligence was going to reinvent the entire computing stack. And if we were ever going to understand how to navigate ourselves and how to guide the industry towards this new future, we have to get good at building the entire stack.**
我们在八年前开始研究自驾车。原因是由于我们很早就推理出深度学习和人工智能将重塑整个计算堆栈。如果我们要想了解如何引导自己并引导行业走向这个新未来，我们就必须擅长构建整个堆栈。

**Well, as I mentioned earlier, AI is a five layer cake. The lowest layer is land power and shell. In the case of robotics, the lowest layer is the car. The next layer above it is chips, GPUs, networking chips, CPUs, all that kind of stuff. The next layer above that is the infrastructure. That infrastructure in this particular case as I mentioned with physical AI is omniverse and cosmos. And then above that are the models. And in the case of the models above that I just shown you. The model here is called Alpamo. And Alpamo today is open sourced.**
嗯，正如我之前提到的，AI 是一个五层蛋糕。最底层是土地、电力和外壳。在机器人的情况下，最底层是汽车。上面一层是芯片，GPU、网络芯片、CPU，所有这类东西。再上面一层是基础设施。在这种特定的情况下，正如我在物理 AI 中提到的，基础设施是 Omniverse 和 Cosmos。再上面是模型。在刚才向你们展示的模型案例中，这里的模型叫作 Alpamo。而 Alpamo 今天开源了。

**We this incredible body of work. It took several thousand people. Our AV team is several thousand people. Just to put in perspective, our partner uh Ola, I think Ola's here in the audience somewhere. Uh Mercedes agreed to partner with us five years ago to go make all of this possible. We imagine that someday a billion cars on a road will all be autonomous. You could either have it be a robo taxi that you're you're you're orchestrating and and renting from somebody or you could own it and is driving for driving by itself or you could decide to drive for yourself and so but every single car will have autonomous vehicle capability. Every single car will be AI powered and so the the the model layer in this case is Alpamo and the application above that is the Mercedes-Benz. Okay.**
我们这项不可思议的工作动用了几千人。我们的自动驾驶（AV）团队有几千人。为了说明这一点，我们的合作伙伴 Ola——我想 Ola 可能在观众席的某个地方。梅赛德斯五年前同意与我们合作，让这一切成为可能。我们设想，有一天路上的十亿辆汽车都将是自动驾驶的。它可以是你可以租用的无人驾驶出租车，或者你可以拥有它并让它自己驾驶，或者你也可以决定自己驾驶，但每一辆车都将具备自动驾驶能力。每一辆车都将由 AI 驱动，所以在这个案例中，模型层是 Alpamo，而其上的应用层是梅赛德斯-奔驰。好的。

---

## 29. 上路计划与安全认证

**And so, so this entire stack is our first Nvidia first entire stack endeavor and we've been working on it for this entire time and I'm just so happy that the first AV car from Nvidia is going to be on the road in Q1 and then it goes Europe in Q2 here in the United States in Q1 then Europe in Q2 and I think it's Asia in Q3 and Q4 and the powerful thing is that we're going to keep on updating it with next ver next versions of Alpamo and versions after that.**
所以，整个堆栈是 NVIDIA 的第一个全栈努力，我们一直都在为此工作，我非常高兴 NVIDIA 的第一辆自动驾驶汽车将于第一季度上路——第一季度在美国，然后第二季度在欧洲，我想第三和第四季度是在亚洲；而强大之处在于我们将不断用 Alpamo 的后续版本对其进行更新。

**There's no question in my mind now that this is going to be one of the largest robotics industries and I'm so happy that we worked on it and it taught us enormous amount about how to help the rest of the world build robotic systems. That deep understanding in knowing how to build it ourselves, building the entire infrastructure ourselves and knowing what kind of chips a robotic system would would need. In this partic particular case, dual Orins, the next generation dual Thors. These processors are designed for robotic systems and was designed for the safe highest level of safety capability. This car just got rated. It just went to production. The Mercedes-Benz CLA was just rated by NCAP, the world's safest car.**
在我心中毫无疑问，这将是最大的机器人产业之一，我很高兴我们研究了它，它教会了我们大量关于如何帮助世界其他地方构建机器人系统的知识。那是关于如何自己构建它的深刻理解，自己构建整个基础设施，并了解机器人系统需要什么样的芯片。在这个特定案例中，是双 Orin，以及下一代的双 Thor。这些处理器是为机器人系统设计的，并且是为最高安全级别的能力而设计的。这辆车刚评完级。它刚投入生产。梅赛德斯-奔驰 CLA 刚刚被 NCAP 评定为世界上最安全的汽车。


## 30. 自动驾驶的双重安全堆栈

**It is the only system that I know that has every single line of code, the chip, the system, every line of code safety certified. The entire model system is based on a sensors are diverse and redundant and so is the self-driving car stack.**
这是我所知道的唯一一个每一行代码、芯片、系统，以及每一行代码都经过安全认证的系统。整个模型系统建立在多样化且冗余的传感器基础之上，自动驾驶汽车堆栈也是如此。

**The Alpamo stack is trained end to end and has incredible skills. However, nobody knows until you drive it forever that it's going to be perfectly safe. And so that we the way we guard rail that is with another software stack, an entire AV stack underneath.**
Alpamo 堆栈是端到端训练的，拥有不可思议的能力。然而，除非你永远开下去，否则没人知道它是否百分之百安全。所以，我们为其设置护栏的方式是使用另一个软件堆栈，即下方的一个完整自动驾驶（AV）堆栈。

**That entire AV stack is built to be fully traceable and it's taken us some five years to build that some six, seven years actually to build that second stack. These two software stacks are mirroring each other and then we have a policy and safety evaluator decide is this something that I'm very confident and can reason about driving very safely.**
那个完整的 AV 堆栈被构建为完全可追溯的，我们花了大约五年时间——实际上是六七年——来构建这第二个堆栈。这两个软件堆栈互为镜像，然后我们有一个策略与安全评估器来决定：这是不是我非常有信心、并且可以推理出能非常安全驾驶的情况。

**If so, I'm going to have Alpamo do it. If it's a circumstance that I'm not very confident in and the safety um policy evaluator decide that we're going to go back to a a very a simpler, safer guard rail system, then it goes back to the classical AV stack.**
如果是，我就让 Alpamo 来处理。如果是在我不大有信心的情况下，且安全策略评估器决定我们要退回到一个更简单、更安全的护栏系统，那么它就会退回到传统的 AV 堆栈。

**Where the only car in the world with both of these AV stacks running and all safety systems should have diversity and redundancy.**
这是世界上唯一运行这两套 AV 堆栈的汽车，所有的安全系统都应该具备多样性和冗余性。

---

## 31. 愿景与垂直整合

**Well, our vision is that someday every single car, every single truck will be autonomous. And we've been working towards that future. This entire stack is vertically integrated. Of course, in the case of Mercedes-Benz, we built the entire stack together.**
嗯，我们的愿景是，总有一天，每一辆轿车、每一辆卡车都将是自动驾驶的。我们一直朝着那个未来努力。整个堆栈是垂直整合的。当然，在梅赛德斯-奔驰的案例中，我们是一起构建了整个堆栈。

**We're going to deploy the car. We're going to operate the stack. We're going to maintain the stack for as long as we shall live.**
我们将部署这辆车。我们将运行这个堆栈。只要我们还在，我们就会一直维护这个堆栈。

---

## 32. 开放生态与 L4 机器人出租车

**However, like everything else we do as a company, we build the entire stack, but the entire stack is open for the ecosystem. And these the ecosystem working with us to build L4 and robo taxis is expanding and it's going everywhere.**
然而，就像我们作为一家公司所做的其他所有事情一样，我们构建了整个堆栈，但整个堆栈对生态系统是开放的。与我们合作构建 L4 级自动驾驶和无人驾驶出租车（Robotaxi）的生态系统正在扩张，并走向各地。

**I fully expect this to be well this is already a giant business for us. It's a giant business for us because they use it for training our training data, processing data and training their models.**
我完全预料到这将成为——事实上这已经是我们的一项巨大业务。这对我们来说是一项巨大业务，因为他们使用它来训练数据、处理数据并训练他们的模型。

**They use it for synthetic data generation in some cases. In some car, in some companies, they pretty much just build uh the computers, the chips that are inside the car. And some companies work with us full stack. Some companies work with us some partial part of that.**
在某些情况下，他们将其用于合成数据生成。在某些汽车公司，他们几乎只使用车载电脑和芯片。有些公司与我们进行全栈合作，有些公司则与我们进行部分合作。

**Okay. So, it doesn't matter uh how much you decide to use. You know, my only request is use a little bit of video wherever you can and uh you know, but uh the entire thing is open.**
好，所以无论你决定使用多少都没关系。你知道，我唯一的请求是尽可能多用一点视频，但整个系统是开放的。

---

## 33. 物理 AI 的转折点

**Now this is going to be the first largescale mainstream um AI physical AI market and this is now I think we can all agree fully here and this inflection point of going from not autonomous vehicles to autonomous vehicles is probably happening right about this time.**
这将是第一个大规模主流的 AI 物理 AI 市场。我想我们在这里都能完全达成共识，从非自动驾驶汽车到自动驾驶汽车的转折点，可能就在此时此刻发生。

**In the next 10 years I'm fairly certain a very very large percentage of the world's cars will be autonomous or highly autonomous.**
在接下来的 10 年里，我相当肯定，世界上非常大比例的汽车将是自动驾驶或高度自动驾驶的。

---

## 34. 机器人时代的到来

**But this basic technique that I just described in using the three computers using synthetic data generation and simulation applies to every form of robotic systems.**
但我刚才描述的使用三台计算机、合成数据生成和模拟的基础技术，适用于各种形式的机器人系统。

**It could be a robot that is just an articulator, a manipulator, maybe it's a mobile robot, maybe it's a fully humanoid robot. And so the next journey, the next era for robotic systems is going to be, you know, robots.**
它可以是一个仅有关节连接、有机械臂的机器人，也可以是一个移动机器人，或者是一个完全的人形机器人。所以机器人系统的下一个旅程、下一个时代，就是机器人（本身）。

**And these robots are going to come in all kinds of different sizes. And and uh I invited some friends. Did they come? Hey guys, hurry up. I got a lot of stuff to cover. Come on, hurry.**
这些机器人会有各种不同的尺寸。而且……我邀请了一些朋友。他们来了吗？嘿伙计们，快点。我还有很多内容要讲。快，快点。

---

## 35. 机器人互动与 Isaac 模拟器

**Did you tell R2-D2 you were going to be here? Did you? And C3PO. Okay. All right. Come here. Before now, one of the things that one of the things that's really You have Jetson's. They have little Jetson computers inside them. They're trained inside Omniverse.**
你告诉 R2-D2 你要来这儿了吗？告诉了吗？还有 C3PO。好的，来吧。在此之前，有一件事真的很特别：你们有 Jetson，它们体内有小巧的 Jetson 电脑。它们是在 Omniverse 内部训练出来的。

**And how about this? Let's show everybody the simulator that you were that you guys learned how to how to be robots in. You You guys want to look at that? Okay, let's look at that. Run it, please.**
这样如何？让我们给大家展示一下你们学习如何成为机器人的模拟器。你们想看吗？好的，让我们看看，请播放。

**See? Is it amazing? That's how you learn to be a robot. You did it all inside Omniverse. And the robot simulators called Isaac. Isaac Sim and Isaac Lab.**
看到了吗？是不是很神奇？这就是你们学习成为机器人的方式。你们完全是在 Omniverse 内部完成的。这个机器人模拟器叫作 Isaac：Isaac Sim 和 Isaac Lab。

---

## 36. 庞大的机器人合作伙伴群

**And anybody who wants to build a robot, you know, nobody could nobody's going to be as cute as you. But now we have all Look at all these look at all these friends that we have building robots.**
任何想要建造机器人的人——你知道，没人能像你们这么可爱。但现在我们有了……看看这些正在建造机器人的伙伴们。

**We have We're building big ones. No, like I said, nobody's as cute as you guys are. But we have Neurobot and we have we have Agubot. Agubot over there, you know. We have uh uh LG over here. They just announced a new robot. Caterpillar. They've got the largest robots ever.**
我们有……我们正在建造大家伙。不，就像我说的，没人像你们这么可爱。但我们有 Neurobot，我们有 Agubot。看那边的 Agubot。我们这边还有 LG，他们刚发布了一款新机器人。还有卡特彼勒（Caterpillar），他们拥有史上最大的机器人。

**That one delivers food to your house. That's connected to Uber Eats. And that's Surf Robot. I love those guys. Agility. Boston Dynamics. Incredible. You got surgical robots. You got manipulator robots from Franka.**
那个是给你们家送外卖的，它连接着 Uber Eats。那是 Serve Robot，我喜欢那些家伙。Agility，波士顿动力（Boston Dynamics），不可思议。还有手术机器人，还有来自 Franka 的机械臂机器人。

**You got universal robotics robot. Incredible number of different robots. And so this is the next chapter. We're going to talk a lot more about robotics in the future.**
还有优傲机器人（Universal Robots）。不同种类的机器人数量惊人。所以这是下一个章节。未来我们会讨论更多关于机器人的话题。

---

## 37. 物理 AI 赋能芯片与系统设计

**But it's not just about the robots in the end. I know everything's about you guys. It's about getting there. And one of the areas one of the most important industries in the world that will be revolutionized by physical AI and AI physics is the industry that started all of us at NVIDIA.**
但归根结底，不只是关于机器人。我知道，对你们来说一切都与你们有关。但这关乎于实现目标。而世界上最重要的、将被物理 AI 和 AI 物理学彻底改变的领域之一，就是开启了我们 NVIDIA 征程的那个行业。

**It wouldn't be possible if not for the companies that I'm about to talk to. And I'm so happy that all of them starting with Cadence is going to accelerate everything. Cadence CUDA X integrated into all of their simulations and solvers.**
如果没有我即将谈到的这些公司，这一切都不可能实现。我非常高兴，从 Cadence 开始，所有的公司都将加速一切。Cadence 的 CUDA-X 集成到了他们所有的模拟器和求解器中。

**They've got uh NVIDIA physical physical AIs that they're going to use for uh for different um physical plants and plant simulations. You got AI physics being integrated into these systems. So whether it's an EDA or SDA um and in the future robotic systems, we're going to have basically the same technology that made you guys possible now completely revolutionize these design stacks.**
他们拥有 NVIDIA 的物理 AI，将用于不同的物理工厂和工厂模拟。AI 物理学正被集成到这些系统中。因此，无论是 EDA（电子设计自动化）还是 SDA（系统设计自动化），以及未来的机器人系统，我们基本上将使用使你们成为可能的相同技术，来彻底改变这些设计堆栈。

---

## 38. 芯片设计的三巨头：Synopsis 与 Cadence

**Synopsis without Synopsis, you know, synopsis and cadence are completely completely indispensable in the world of chip design. uh synopsis is uh leads in uh in uh logic design and and IP uh in the case of cadence they lead physical design the place and route uh and emulation and verification.**
Synopsys——如果没有 Synopsys，你知道，Synopsys 和 Cadence 在芯片设计领域是完全不可或缺的。Synopsys 在逻辑设计和 IP 领域处于领先地位；而 Cadence 在物理设计、布局布线、以及仿真和验证方面处于领先地位。

**Cadence is incredible at emulation and verification. Both of them are moving into the world of system design and system simulation. And so in the future we're going to design your chips inside Cadence and inside Synopsis. We're going to design your systems and emulate the whole thing and simulate everything inside these tools.**
Cadence 在仿真和验证方面非常出色。这两家公司都在向系统设计和系统模拟领域迈进。所以在未来，我们将在 Cadence 和 Synopsys 内部设计你们的芯片。我们将设计你们的系统，并在这些工具内部对整个系统进行仿真和模拟。

**That's your future. We're going to give Yeah. You're going to be born inside these inside these platforms. Pretty amazing, right?**
这就是你们的未来。是的。你们将在这些平台内部“诞生”。非常神奇，对吧？

---

## 39. 与西门子的深度合作

**And so we're so happy that we're working with these these industries just as we've integrated NVIDIA into Palunteer and Service Now. We're integrating Nvidia into the most computationally intensive simulation industries, Synopsis and Cadence.**
所以我们非常高兴能与这些行业合作，就像我们将 NVIDIA 集成到 Palantir 和 ServiceNow 一样。我们也正在将 NVIDIA 集成到计算密集度最高的模拟行业：Synopsys 和 Cadence。

**And today we're announcing that Seammens is also doing the same thing. We're going to integrate CUDA X physical AI agentic AI Nemo Neotron deeply integrated into the world of Seammens.**
今天，我们宣布西门子（Siemens）也在做同样的事情。我们将把 CUDA-X、物理 AI、智能体 AI、Nemo、Nemotron 深度集成到西门子的世界中。

**And the reason for that is this. First, we designed the chips and all of it in the future will be accelerated by Nvidia. You're going to be very happy about that. We're going to have Agentic chip designers and system designers working with us, helping us do design just as we have agentic software engineers helping our software engineers code today.**
原因是：首先，我们设计芯片，未来所有这些都将由 NVIDIA 加速。你会为此感到很高兴。我们将有“智能体芯片设计师”和“系统设计师”与我们合作，帮助我们进行设计，就像我们今天有智能体软件工程师帮助我们的软件工程师编写代码一样。

---

## 40. 数字孪生工厂：制造机器人的机器人

**And so we'll have agentic chip designers and system designers. We're going to create you inside this. But then we have to build you. We have to build the plants, the factories that make manufacture you. We have to design the manufacturing lines that assemble all of you.**
所以我们将拥有智能体芯片设计师和系统设计师。我们将在其中创造你们。但随后我们必须制造你们。我们必须建造生产你们的厂房和工厂。我们必须设计组装你们所有人的生产线。

**And these manufacturing plants are going to be essentially gigantic robots. Incredible, isn't that right? I know. I know.**
而这些制造工厂本质上将是巨大的机器人。不可思议，不是吗？我知道，我知道。

**And so, you're going to be designed in a computer. You're going to be made in a computer. You're going to be tested and evaluated in a computer long before long before you have to spend any time dealing with gravity.**
所以，你们将在电脑中被设计。你们将在电脑中被制造。你们将在电脑中接受测试和评估，早在你们不得不花时间应对重力之前。

**I know. Do you know how to deal with gravity? Can you jump? Can you jump? Okay. All right. Don't show off.**
我知道。你知道怎么应对重力吗？你会跳吗？你会跳吗？好吧，别炫耀了。

---

## 41. 赋能制造业：西门子视频演示

**So this so now the industry the industry that made Nvidia possible. We're I'm just so happy that that now the technology that we're creating is at a level of sophistication and capability that we can now help them revolutionize their industry.**
所以，这个曾经成就了 NVIDIA 的行业，我现在非常高兴，我们现在创造的技术已经达到了如此高的成熟度和能力水平，以至于我们现在可以帮助他们彻底改变他们的行业。

**And so what started with with uh with them, we now have the opportunity to go back and and help them revolutionize theirs. Let's take a look at the stuff that we're going to do with Seammens. Come on.**
所以，从他们那里开始的一切，我们现在有机会回去帮助他们彻底改变他们的行业。让我们看看我们要和西门子一起做的事情。请看。

**Breakthroughs in physical AI are letting AI move from screens to our physical world. And just in time, as the world builds factories of every kind for chips, computers, life-saving drugs, and AI, as the global labor shortage worsens, we need automation powered by physical AI and robotics more than ever.**
物理 AI 的突破正让 AI 从屏幕走向我们的物理世界。正当其时，全球正为芯片、计算机、救命药物和 AI 建造各种工厂，随着全球劳动力短缺的加剧，我们比以往任何时候都更需要由物理 AI 和机器人驱动的自动化。

**This where AI meets the world's largest physical industries is the foundation of NVIDIA and Seaman's partnership. For nearly two centuries, Seammens has built the world's industries and now it is reinventing it for the age of AI.**
AI 与全球最大物理产业的交汇，正是 NVIDIA 与西门子伙伴关系的基础。近两个世纪以来，西门子构建了世界的工业，现在它正在为 AI 时代重塑工业。

**Semens is integrating NVIDIA CUDA X libraries, AI models, and Omniverse into its portfolio of EDA, CAE, and digital twin tools and platforms. Together, we're bringing physical AI to the full industrial life cycle. From design and simulation to production and operations, we stand at the beginning of a new industrial revolution.**
西门子正在将 NVIDIA CUDA-X 库、AI 模型和 Omniverse 集成到其 EDA、CAE 和数字孪生工具及平台组合中。通过合作，我们将物理 AI 带入整个工业生命周期。从设计、模拟到生产和运营，我们正处于新工业革命的开端。

---

## 42. Vera Rubin：以天文学家命名的新架构

**Incredible, right guys? What do you think? All right. Well, hang on tight. Just hang on tight. And so, so this is, you know, if you look at look at the world's models, there's no question OpenAI is the the the leading token generator today.**
很神奇，对吧伙计们？你们觉得呢？好了，坐稳了，请坐稳。所以，如果你看看世界的模型，毫无疑问，OpenAI 是当今领先的 Token（生成单位）生成器。

**More to more open AAI tokens are generated than just about anything else. The second largest group, the second largest probably open models.**
生成的 OpenAI Token 比其他任何东西都多。第二大群体，可能就是开源模型。

**And my guess is that over time because there are so many companies, so many researchers, so many different types of domains and modalities that open-source models will be by far the largest.**
我的猜测是，随着时间的推移，由于有这么多公司、这么多研究人员、这么多不同类型的领域和模态，开源模型将成为迄今为止规模最大的群体。

**Let's talk about somebody really special. You guys want to do that? Let's talk about Vera Rubin. Vera Rubin. Yeah, go ahead. She's a American astronomer. She was the first to observe. She noticed that the tails of the galaxies were moving about as fast as the center of the galaxies.**
让我们谈谈一个非常特别的人。你们想聊聊吗？让我们谈谈薇拉·鲁宾（Vera Rubin）。是的，薇拉·鲁宾。她是一位美国天文学家。她是第一个观察到——她注意到星系边缘的移动速度几乎和星系中心一样快的人。

**Well, I know it makes no sense. It makes no sense. Newtonian physics would say just like the solar system, the planets further away from the sun is circulating circ cir circling the sun slower than the planets closer to the sun.**
我知道，这不合常理。这完全不合理。牛顿物理学会说，就像太阳系一样，离太阳越远的行星绕太阳旋转的速度应该比离太阳近的行星慢。

**And therefore it makes no sense that this happens unless there's invisible bodies we call them she discovered dark body dark matter um that occupy space even though we don't see it and so Vera Rubin is the person that we named our next computer after. Isn't that a good idea?**
因此，除非存在我们称之为“不可见天体”的东西，否则这种情况发生是不合理的。她发现了占据空间但我们看不见的暗物质。所以，薇拉·鲁宾就是我们下一代计算机命名的对象。这是个好主意，不是吗？

---

## 43. 推理成本与计算需求的爆炸

**Vera Rubin is designed to address this fundamental challenge that we have. The amount of computation necessary for AI is skyrocketing. The demand for NVIDIA GPUs is skyrocketing. It's skyrocketing because models are increasing by a factor of 10, an order of a magnitude every single year.**
Vera Rubin 旨在解决我们面临的根本挑战。AI 所需的计算量正在飙升。对 NVIDIA GPU 的需求正在飙升。之所以飙升，是因为模型每年都在以 10 倍（一个数量级）的速度增长。

**And not to mention, as I mentioned, 01's introduction was an inflection point for AI. Instead of a oneshot answer, inference is now a thinking process. And in order to teach the AI how to think, reinforcement learning and very significant computation was introduced into post training.**
更不用说，正如我提到的，o1 的推出是 AI 的一个转折点。推理现在不再是一次性的回答，而是一个思考过程。为了教 AI 如何思考，在后训练阶段引入了强化学习和极其庞大的计算量。

**It wasn't no long it's no longer supervised fine-tuning or otherwise known as imitation learning or supervision training. You now have reinforcement learning essentially the computer trial trying different iterations itself learning how to perform a task.**
它不再仅仅是监督微调，或者说模仿学习、监督训练。你现在有了强化学习，本质上是计算机自己尝试不同的迭代，学习如何执行任务。

**The amount of computation for pre pre-training for post-trainining for test time scaling has exploded as a result of that. And now every single inference that we do instead of just one shot the number of tokens you could just see the AI think which we appreciate. The longer it thinks oftentimes it produces a better answer.**
预训练、后训练以及推理时缩放（test-time scaling）的计算量因此爆炸式增长。现在，我们进行的每一次推理不再只是“一锤子买卖”，你可以看到 AI 在思考生成的 Token 数量，我们对此表示赞赏。它思考得越久，通常产生的答案就越好。

**And so test time scaling causes the number of tokens to be generated to increase by 5x every single year.**
因此，推理时缩放导致每年生成的 Token 数量增长了 5 倍。

---

## 44. 性能提升竞赛与极简协同设计

**Not to mention, meanwhile, the race is on for AI. Everybody's trying to get to the next level. Everybody's trying to get to the next frontier. And every time they get to the next frontier, the last generation AI tokens, the cost starts to starts to decline about a factor of 10x every year.**
更不用说，与此同时，AI 的竞赛已经开启。每个人都试图达到下一个水平。每个人都试图到达下一个前沿。每当他们到达下一个前沿时，上一代 AI Token 的成本就开始以每年约 10 倍的速度下降。

**The 10x decline every year is actually telling you something different. It's saying that the race is so intense. Everybody's trying to get to the next level and somebody is getting to the next level. And so therefore, all of it is a computing problem.**
每年 10 倍的降价实际上在告诉你另一件事：竞赛非常激烈。每个人都在努力迈向下一个台阶，而且总有人能做到。因此，归根结底，这都是一个计算问题。

**The faster you compute, the sooner you can get to the next level of the next frontier. All of these things are simultaneously happening at the same time. And so we decided that we have to advance the state-of-the-art of computation every single year. Not one year left behind.**
你计算得越快，你就越早能到达下一个前沿的台阶。所有这些事情都在同时发生。所以我们决定，我们必须每年都提升计算的最前沿水平。一年都不能落下。

---

## 45. Vera Rubin 全面投产

**And now we've been shipping GB200s year and a half ago. Right now we're in fullscale manufacturing of GB300. And if Vera Rubin is going to be in time for this year, it must be in production by now. And so today I can tell you that Vera Rubin is in full production.**
一年半前我们开始出货 GB200。现在我们正在全面制造 GB300。如果 Vera Rubin 要赶在今年上市，它现在必须已经投产了。所以今天我可以告诉你们，Vera Rubin 已经全面投产。

**You guys want to take a look at Vera Rubin? All right, come on. Play it, please.**
你们想看看 Vera Rubin 吗？好的，来吧，请播放视频。

---

## 46. Vera Rubin 视频解说：六枚芯片合而为一

**Vera Rubin arrives just in time for the next frontier of AI. This is the story of how we built it. The architecture, a system of six chips engineered to work as one, born from extreme code design.**
Vera Rubin 正好在 AI 的下一个前沿领域到来之际问世。这是我们如何打造它的故事。该架构是由六枚芯片组成的系统，旨在协同工作，诞生于极端的协同设计（Co-design）。

**It begins with Vera, a custom-designed CPU, double the performance of the previous generation. And the Reuben GPU, Vera and Reuben are co-designed from the start to birectionally and coherently share data faster and with lower latency.**
它始于 Vera，这是一款定制设计的 CPU，性能是上一代的两倍。还有 Rubin GPU，Vera 和 Rubin 从一开始就是协同设计的，旨在更快、更低延迟地双向、一致地共享数据。

**Then 17,000 components come together on a Ver Rubin compute board. High-speed robots place components with micron precision before the Vera CPU and two Reuben GPUs complete the assembly.**
接着，17,000 个组件在 Vera Rubin 计算板上汇聚。高速机器人在 Vera CPU 和两枚 Rubin GPU 完成组装之前，以微米级的精度放置组件。

**Capable of delivering 100 pedaflops of AI, five times that of its predecessor. AI needs data fast. Connect X9 delivers 1.6 terabs per second of scale out bandwidth to each GPU.**
它能够提供 100 Petaflops 的 AI 性能，是其前代的 5 倍。AI 需要快速的数据。ConnectX-9 为每颗 GPU 提供 1.6 Tbps 的横向扩展带宽。

**Bluefield 4 DPU offloads storage and security so compute stays fully focused on AI. The Vera Rubin compute tray completely redesigned with no cables, hoses, or fans. Featuring a Bluefield 4 DPU, eight Connect X9 Nix, two Vera CPUs, and four Reuben GPUs, the compute building block of the Vera Rubin AI supercomputer.**
Bluefield-4 DPU 卸载了存储和安全任务，使计算能够完全专注于 AI。Vera Rubin 计算托盘经过完全重新设计，没有电缆、软管或风扇。它配备了一颗 Bluefield-4 DPU、八个 ConnectX-9 网卡、两颗 Vera CPU 和四颗 Rubin GPU，是 Vera Rubin AI 超级计算机的计算构建模块。

**Next, the sixth generation MVLink switch, moving more data than the global internet, connecting 18 compute nodes, scaling up to 72 Reuben GPUs, operating as one.**
接下来是第六代 NVLink 交换机，其传输的数据量超过全球互联网，连接了 18 个计算节点，可扩展至 72 颗 Rubin GPU，像单体一样运作。

**Then Spectrum X Ethernet Photonix, the world's first Ethernet switch with 512 lanes and 200 Gbit capable co-packaged optics scale out thousands of racks into an AI factory. 15,000 engineer years since design began, the first Vera Rubin MVL 72 rack comes online. Six breakthrough chips, 18 compute trays, nine MVLink switch trays, 220 trillion transistors weighing nearly two tons. One giant leap to the next frontier of AI. Reuben is here.**
然后是 Spectrum-X 以太网光子技术（Photonics），全球首款拥有 512 通道和 200Gbps 能力的共封装光学器件（CPO）以太网交换机，可将数千个机架扩展为 AI 工厂。自设计开始以来耗费了 1.5 万个工程师年，首个 Vera Rubin NVL72 机架上线。六枚突破性芯片，18 个计算托盘，9 个 NVLink 交换机托盘，220 万亿个晶体管，重达近两吨。这是迈向 AI 下一个前沿领域的一大步。Rubin 来到了我们身边。

---

## 47. 硬件参数：极端的协同设计

**This is a Reuben pod. 1152 GPUs in 16 racks. Each one of the racks as you know has uh 72 Vera Rubin or 72 Reubins. Each one of the Reubins is two actual GPU dies connected together.**
这是一个 Rubin Pod。16 个机架中包含 1152 颗 GPU。如你所知，每个机架拥有 72 颗 Vera CPU 或 72 颗 Rubin GPU。每一颗 Rubin 实际上是两个连接在一起的 GPU 晶圆。

**We designed six different chips. First of all, we have a rule inside our company, and it's a good rule. No new generation should have more than one or two chips change.**
我们设计了六种不同的芯片。首先，我们公司内部有一条规则，而且这条规则很好：每一代新产品不应更换超过一到两颗芯片。

**But the problem is this. As you could see, we were describing the total number of transistors in each one of the chips that were being described. And we know that Moore's law has largely slowed.**
但问题是这样的。正如你所看到的，我们在描述每一颗芯片的晶体管总数，而我们知道摩尔定律已大大放缓。

**And so the number of transistors we can get year after year after year can't possibly keep up with the 10 times larger models. It can't possibly keep up with five times per year more tokens generated.**
因此，我们逐年获得的晶体管数量，根本无法跟上模型大 10 倍的速度。它根本跟不上每年 Token 生成量增长 5 倍的速度。

**It is impossible to keep up with those kind of rates if the industry for the industry to continue to advance unless we deployed aggressive extreme code design basically innovating across all of the chips across the entire stack all at the same time.**
如果行业要继续前进，就无法维持这种速度，除非我们采用激进的“极端协同设计”——基本上是同时对整个堆栈中的所有芯片进行创新。

**Which is the reason why we decided that this generation we had no choice but to design every chip over again.**
这就是为什么我们决定这一代产品别无选择，只能重新设计每一颗芯片的原因。

---

## 48. Vera CPU 与 Rubin GPU 性能

**The Vera CPU I'm so proud of it in a power constrained world. Gray CPU is two times the performance in a power constrained world. It's twice the performance per watt of the world's most advanced CPUs.**
我为 Vera CPU 感到非常自豪。在电力受限的世界中，Grace CPU 的性能已经很出色，而 Vera CPU 的性能是其两倍。它的每瓦性能是世界上最先进 CPU 的两倍。

**Its data rate is insane. It was designed to process supercomputers and Vera was an incredible GPU. Now Vera increases the singlethreaded performance, increases the capacity of the memory, increases everything just dramatically. It's a giant chip. This is the Vera CPU. This is one CPU.**
它的数据传输率高得离谱。它是为处理超级计算机而设计的。Vera 极大地提升了单线程性能，提升了内存容量，极大提升了一切。它是一颗巨大的芯片。这就是 Vera CPU，一颗 CPU。

**And this is connected to the Reuben GPU. Look at that thing. It's a giant chip.**
而这颗 CPU 连接着 Rubin GPU。看看那家伙，一颗巨大的芯片。

**The Rubin GPU is 5x blackwell in floating performance. But the important thing is go to the bottom line. It's only 1.6 times the number of transistors of black wall.**
Rubin GPU 的浮点性能是 Blackwell 的 5 倍。但重要的是看底线：它的晶体管数量仅为 Blackwell 的 1.6 倍。

**If we don't do code design, if we do don't do extreme code design at the level of basically every single chip across the entire system, how is it possible we deliver performance levels that is, you know, at best one point 1 1.6 times each year?**
如果我们不做协同设计，如果不从整个系统的每一颗芯片层面进行极端协同设计，我们怎么可能每年提供——你知道，在最好的情况下也只有 1.1 到 1.6 倍的性能提升？

---

## 49. NV-FP4 与 Transformer 引擎的革命

**Well, one of the things that we did and it was a great invention. It's called MVF FP4 tensor core. The transformer engine inside our chip is not just a 4bit floatingpoint number somehow that we put into the data path.**
嗯，我们做的一件事是一项伟大的发明。它被称为 NV-FP4 Tensor Core。我们芯片内部的 Transformer 引擎不仅仅是我们将某个 4 位浮点数放入数据路径。

**It is an entire processor, a processing unit that understands how to dynamically adaptively adjust its precision and structure to deal with different levels of the transformer so that you can achieve higher throughput wherever it's possible to lose precision and to go back to the highest possible precision wherever you need to.**
它是一个完整的处理器，一个处理单元，它懂得如何动态、自适应地调整精度和结构，以处理 Transformer 的不同层，从而在允许损失精度的地方获得更高的吞吐量，而在需要高精度的地方返回最高精度。

**This is groundbreaking work. I would not be surprised that the industry would like us to make this format and this structure an industry standard in the future.**
这是开创性的工作。如果未来行业希望我们将这种格式和结构作为行业标准，我一点也不会感到惊讶。

---

## 50. 制造与组装：从 2 小时到 5 分钟

**Look at this. This is the last one. We revolutionized the entire MGX chassis. This node 43 cables, zero cables, six tubes, just two of them here. It takes two hours to assemble this. If you're lucky, it takes two hours.**
看这个。这是最后一个。我们彻底改变了整个 MGX 机箱。这个节点有 43 根电缆——现在是零电缆；六根管子——这里只有两根。以前组装这个需要两小时。如果你运气好，需要两小时。

**This from two hours to 5 minutes. 80% liquid cooled. 100% liquid cooled. Yeah. Really, really a breakthrough.**
现在从两小时缩短到了 5 分钟。从 80% 液冷提升到了 100% 液冷。是的，这真的是一个突破。

---

## 51. 网络技术：Spectrum-X 与 ConnectX-9

**And what connects all of these to the top of rack switches, the east west traffic is called the Spectrumx nick. This is the world's best nick. Unquestionably, Nvidia's Melanox, the acquisition Melanox that joined us a long time ago now.**
将所有这些连接到机架顶端交换机（东西向流量）的东西叫作 Spectrum-X 网卡。这是世界上最好的网卡。毫无疑问，这是 NVIDIA 的 Mellanox——很久以前加入我们的 Mellanox 团队的成果。

**NVIDIA today is the largest networking company the world has ever seen. The performance is incredible especially when you have a 200 um megawatt data center or if you have a gigawatt data center. These are billions of dollars.**
NVIDIA 今天是世界上前所未见的最大的网络公司。性能令人惊叹，特别是当你拥有一个 200 兆瓦的数据中心或一个吉瓦级的数据中心时。这些都是价值数十亿美元的设施。

**Let's say a gigawatt data center is $50 billion. If the networking performance allows you to deliver an extra 10% in the case of Spectrum X, delivering 25% higher throughput is not uncommon. If we were to just deliver 10% that's worth $5 billion. The networking is completely free, which is the reason why, well, everybody uses Spectrum X.**
假设一个吉瓦级数据中心价值 500 亿美元。如果网络性能允许你额外提升 10%——在 Spectrum-X 的情况下，提升 25% 的吞吐量并不罕见——如果我们只提升 10%，那就价值 50 亿美元。这意味着网络设备完全是白送的，这就是为什么大家都在用 Spectrum-X 的原因。

---

## 52. NVLink 6 与 硅光子交换机

**This is the MVLink 6 switch and it's right here. Each one of these switch chips has the fastest certis in history. The world is barely getting to 200 Gbits. This is 400 Gbits per second switch.**
这就是 NVLink 6 交换机，就在这儿。这些交换机芯片中的每一颗都拥有历史上最快的 SerDes（串行器/解串器）。世界才刚达到 200Gbps，而这是 400Gbps 的交换机。

**This switch on the back plane of one of these racks enables us to move the equivalent of twice the amount of the global internet data, twice as all of the world's internet data at twice the speed.**
这个安装在机架背板上的交换机使我们能够以两倍的速度传输相当于全球互联网数据量两倍的数据。

**You take the cross-sectional bandwidth of the entire planet's internet, it's about 100 terabytes per second. This is 240 terabytes per second.**
如果你算一下整个地球互联网的截面带宽，大约是每秒 100 TB。而这是每秒 240 TB。

---

## 53. KV Cache 与 AI 存储革命

**AI has reinvented the whole computing stack, every layer of the computing stack. It stands to reason that when AI starts to get deployed in the world's enterprises, it's going to also reinvent the way storage is done.**
AI 已经重塑了整个计算堆栈，重塑了堆栈的每一层。理所当然地，当 AI 开始在世界各地的企业中部署时，它也将重塑存储的方式。

**Well, AI doesn't use SQL. AI use semantics information. And when AI is being used, it creates this temporary knowledge, temporary temporary memory calls KV cache, K key value combinations.**
嗯，AI 不使用 SQL。AI 使用语义信息。当 AI 被使用时，它会创建这种临时知识，这种临时存储被称为 KV Cache（键值缓存）。

**The working memory of the AI is stored in the HBO (HBM) memory. Every single token, for every single token, the GPU reads in the model, the entire model. It reads in the entire working memory and it produces one token and it stores that one token back into the KV cache.**
AI 的工作内存存储在 HBM（高带宽内存）中。每一个 Token，对于每一个生成的 Token，GPU 都要读入模型——整个模型。它读入整个工作内存，产生一个 Token，然后将该 Token 存回 KV Cache。

**The idea that we would create a new platform, a new processor to run the entire Dynamo KV cache context memory management system and to put it very close to the rest of the rack is completely revolutionary.**
我们将创建一个新平台、一个新处理器来运行整个 Dynamo KV Cache 上下文内存管理系统，并将其放置在非常靠近机架其余部分的位置，这个想法是完全革命性的。

## 54. 巨大的上下文内存存储

**So this is it. This is it sits right here. So this this is all the compute nodes. Each one of these is MVLink 72.**
就是这个了。它就坐落在这里。这就是所有的计算节点。其中的每一个都是 MVLink 72。

**So this is Vera Rubin MVLink 72 144 Reuben GPUs. This is the context memory that's stored here. Behind each one of these are four blue fields.**
这就是拥有 144 颗 Rubin GPU 的 Vera Rubin MVLink 72 系统。这是存储在这里的上下文内存（Context Memory）。在每一个模块背后都有四颗 Bluefield。

**Behind each blue field is 150 terabytes 150 terabytes of memory context memory. And for each GPU once you allocate it across each GPU will get an additional 16 terabytes.**
在每一颗 Bluefield 背后是 150 TB 的上下文内存。对于每一颗 GPU，一旦你完成分配，每颗 GPU 将获得额外的 16 TB 内存。

**Now inside this node each GPU essentially has one terabyte. And now with this backing store here directly on the same east west traffic at exactly the same data rate 200 gigabits per second across literally the entire fabric of this compute node. You're going to get an additional 16 terabytes of memory.**
现在，在这个节点内部，每颗 GPU 本身拥有 1 TB 内存。而现在有了这个后端存储，它直接位于相同的“东西向流量”上，以完全相同的数据速率——每秒 200 Gbps——贯穿整个计算节点的网络架构。你将获得额外的 16 TB 内存。

---

## 55. 管理平面与网络

**Okay. And this is the management plane. These are these are the spectrum X switches that connects all of them together. And over here, these switches at the end connects them to the rest of the data center. Okay. And so this is the Vera Rubin.**
好了。这是管理平面。这些是 Spectrum-X 交换机，将所有组件连接在一起。而在这一端，这些交换机将它们连接到数据中心的其余部分。好，这就是 Vera Rubin。

---

## 56. 能效突破与 45°C 热水冷却

**Now there are several things that's really incredible about it. So the first thing that I mentioned is that the this entire system is twice the energy efficiency essentially the that twice the the the temperature performance.**
现在，它有几件事确实令人难以置信。我提到的第一件事是，这整个系统的能效基本上是原来的两倍，本质上是两倍的温度调节性能。

**In the sense that that even though the power is twice as high the amount of energy used is twice as high the amount of computation is many times higher than that but the liquid that goes into it still 45 degrees C.**
从某种意义上说，尽管功率高出两倍，使用的能量也高出两倍，但计算量却比这高出许多倍；而且进入系统的液体仍然保持在 45 摄氏度。

**That enables us to save about 6% of the world's data center power. So that's a very big deal.**
这使我们能够节省全球约 6% 的数据中心电量。这是一件非常了不起的大事。

---

## 57. 机密计算与全链路加密

**The second very big deal is that this entire system is now confidential computing safe. Meaning everything is encoded in transit at rest and during compute and every single bus is now encrypted.**
第二件大事是，整个系统现在已经实现了机密计算安全。这意味着所有内容在传输中、静态存储时以及计算过程中都是编码加密的，每一条总线现在也都加密了。

**Every PCI Express, every MV link, every H you know for a MVL link between CPU me and GPU between GPU to GPU, everything is now encrypted and so it's confidential computing safe.**
每一个 PCI Express，每一个 NVLink，你知道，CPU 与 GPU 之间、GPU 与 GPU 之间的 NVLink，一切现在都加密了，所以它是机密计算安全的。

**This allows companies to feel safe that their models are being deployed by somebody else but it will never be seen by anybody else. Okay.**
这让公司感到安全：他们的模型正由别人部署，但永远不会被其他任何人看到。

---

## 58. 功率平滑（Power Smoothing）技术

**And so this particular system is not only incredibly energy efficient and there's one other thing that's incredible because of the nature of the workload of AI it spikes instantaneously.**
所以这个特殊的系统不仅能效惊人，还有另一件令人难以置信的事：由于 AI 工作负载的性质，它会产生瞬间的功率峰值。

**With this computation layer called all reduce the amount of current the amount of energy that is used but simultaneously is really off the charts. Oftentimes it'll spike up 25%.**
在执行被称为“全归约（All-reduce）”的计算层时，电流的使用量和能量的消耗量会同步暴增。它经常会瞬间飙升 25%。

**We now have power smoothing across the entire system so that you don't have to overprovision by 25 times or if you overprovision by 25 times you don't have to leave 25% of the energy um squandered or unused.**
我们现在在整个系统中实现了“功率平滑”，这样你就不必过度预留 25% 的电力冗余，或者说，如果你预留了 25%，你也不必让这 25% 的能量被朗费或闲置。

**And so now you could fill up the entire power budget and you don't have to provision beyond that.**
所以现在你可以填满整个电力预算，而不必为此进行额外的电力扩容。

---

## 59. 性能基准：DeepSeek++ 与 Grok 5

**And then the Last thing of course is performance. So let's take a look at the performance of this. These are only charts that people who build AI super supercomputers would love.**
最后一件事当然就是性能。让我们看看它的性能。这些图表只有建造 AI 超级计算机的人才会喜欢。

**It took exact it took every single one of these chips complete redesign of every single one of the systems and rewriting the entire stack for us to make this possible.**
为了实现这一切，我们需要对每一颗芯片进行精确设计，对每一个系统进行彻底重新设计，并重写整个堆栈。

**Basically this is training the AI model. This first column, the faster you train AI models, the faster you can get the next frontier out to the world. This is your time to market. This is technology leadership. This is your pricing power.**
基本上，这是在训练 AI 模型。第一列显示：训练 AI 模型越快，你就越快能向世界推出下一个前沿成果。这就是你的上市时间。这就是技术领先地位。这就是你的定价权。

**In the case of the green, this is essentially a 10 trillion parameter model. We scaled it up from deepse deepse. That's why we call it deepsee++ a training a 10 trillion parameter model on a 100 trillion tokens.**
在绿色柱状图中，这本质上是一个 10 万亿参数的模型。我们基于 DeepSeek 对其进行了扩展，所以我们称之为 DeepSeek++，它在 100 万亿个 Token 上训练一个 10 万亿参数的模型。

**The next frontier model uh Elon's already mentioned that the next version of Grock Grock 5 I think is 7 trillion parameters. This is 10 and in the green is black. Well, and here in the case of um uh Reuben, notice the throughput is so much higher.**
下一个前沿模型……埃隆（Elon）已经提到过，下一版 Grok——我想是 Grok 5——拥有 7 万亿参数。而这里展示的是 10 万亿。绿色的是 Blackwell，而在 Rubin 的案例中，请注意其吞吐量要高得多。

**And therefore it only takes 1/4th as many of these systems in order to train the model in the time that we gave it here which is one month. Okay. And so time time is the same for everybody.**
因此，在相同的训练时间（我们这里设定为一个月）内，只需要 1/4 的系统就能完成训练。对每个人来说，时间成本都是一样的。

---

## 60. 工厂吞吐量与 Token 成本

**Now how much how fast you can train that model and how large of a model you can train is how you're going to get to the frontier first. The second part is your factory throughput.**
现在，你能训练多快、能训练多大的模型，决定了你如何率先到达前沿。第二部分是你的工厂吞吐量。

**Blackwell is green again. And factory throughput is important because your factory is in the case of a gigawatt is $50 billion. A $50 billion data center can only consume one gigawatt of power.**
绿色再次代表 Blackwell。工厂吞吐量非常重要，因为对于一个吉瓦（10 亿瓦）级的数据中心，其造价高达 500 亿美元。而 500 亿美元的数据中心只能消耗一个吉瓦的电力。

**And so if your performance, your throughput per watt is very good versus quite poor, that directly translates to your revenues. Your revenues of your data center is directly related to the second column.**
因此，如果你的每瓦性能或每瓦吞吐量非常出色，或者表现很差，这会直接转化为你的收入。你数据中心的收入与第二列数据直接相关。

**In the case of Blackwell, it was about 10 times over Hopper. In the case of Reuben, it's going to be about 10 times higher again. Okay. And in the case of now the um the cost of the tokens, how cost effectively it is to generate the token. This is Reuben about one/10enth just as in the case of Yep.**
在 Blackwell 的情况下，它比 Hopper 高出约 10 倍。在 Rubin 的情况下，它将再次提高约 10 倍。至于 Token 成本，即生成 Token 的成本效益，Rubin 的成本大约只有（Blackwell 的）十分之一，没错。

---

## 61. NVIDIA 的定位：全栈系统公司

**So that's how this is how we're going to get everybody to the next frontier to um push AI to the next level and of course to build these data centers energy efficiently and cost efficiently.**
这就是我们将如何把每个人推向下一个前沿，将 AI 提升到下一个水平，当然，也是如何以高能效和高成本效益建造这些数据中心的方式。

**So this is it. This is Nvidia today. You know, we mentioned that we build chips, but as you know, Nvidia builds entire systems now.**
就是这些了。这就是今天的 NVIDIA。你知道，我们提过我们制造芯片，但如你所见，NVIDIA 现在制造的是整个系统。

**And AI is a full stack. We we're reinventing AI across everything from chips to infrastructure to models to applications.**
AI 是一个全栈。我们正在从芯片、基础设施、模型到应用程序的每一个层面重塑 AI。

**And our job is to create the entire stack so that all of you could create incredible applications uh for the rest of the world. Thank you all for coming. Have a great CES.**
我们的工作是创建整个堆栈，以便你们所有人都能为世界其他地方创造出令人惊叹的应用程序。感谢各位的光临，祝大家在 CES 玩得愉快。

---

## 62. 花絮：NVIDIA 的幕后时刻

**Now, before before I before I let you guys go, uh there were a whole bunch of slides we had to cut we had to leave on the cutting floor and so we have some out takes here. I think it'll be fun for you. Have a great CES, guys.**
现在，在让你们离开之前，有一大堆幻灯片被我们删减掉了，留在剪辑室的地板上，所以我们准备了一些花絮片段。我想这对你们来说会很有趣。祝大家 CES 愉快！

**And cut. Nvidia live at CES. Take four. Marker. Boom. Mike action.**
（导演音）停！NVIDIA CES 现场直播。第四次拍摄。打板。砰。麦克风准备，开拍。

**Sorry guys. Platform shift, huh? That should do it. And let's roll camera.**
（黄仁勋）抱歉伙计们。平台转型，哈？应该可以了。摄像机开转。

**A shade of green. A bright happy green. World's most powerful AI supercomput you can plug into the wall next to my toaster.**
一种绿色。一种明快、开心的绿色。世界上最强大的 AI 超级计算机，你可以把它插在墙上，就在我的烤面包机旁边。

**Hey guys, I'm I'm stuck again. I'm so sorry. This slide is never going to work. Let's just cut it. Hello. Can you hear me?**
嘿伙计们，我又卡住了。太抱歉了。这张幻灯片永远行不通。干脆删了吧。喂，能听到我说话吗？

**So, like I was saying, the router. Because not every problem needs the biggest, smartest model. Just the right one.**
所以，就像我说的，路由器。因为不是每一个问题都需要最大、最聪明的模型。只需要最合适的那一个。

**No, no, don't lose any of them. This new six chip Reuben platform makes one amazing AI supercomputer. There you go, little guy.**
不，不，一个都不能少。这个全新的六芯片 Rubin 平台打造了一台令人惊叹的 AI 超级计算机。拿好，小家伙。

**Oh no, no, not the scaling laws. There is a squirrel on the car. Be ready to make the squirrel go away. Ask the squirrel gently to move away.**
噢不，不，别提缩放定律（Scaling Laws）了。车上有一只松鼠。准备好把松鼠弄走。温柔地请松鼠离开。

**Did you know the best models today are all mixture of experts? Hey. Where'd everybody go?**
你知道吗，现在最好的模型都是“专家混合模型（MoE）”？嘿，大家都去哪儿了？

---

**演讲全文翻译完毕。**

### 结语

这场演讲展示了 NVIDIA 已经从一家显卡公司彻底转变为一家**全栈人工智能计算系统公司**。通过 **Vera Rubin**，NVIDIA 再次定义了未来十年的算力底座。

好的，我为你整理了这份带有**原文例句**的深度学习清单。通过这些例句，你可以观察到这些高级表达是如何在真实的科技发布会场景中被运用的。

---

# 💡 黄仁勋 2026 CES 演讲：高级表达与例句库

## 一、 高级固定句式 (Sentence Patterns)


| 序号 | 高级句式 (Advanced Patterns) | 原文例句 (Original Sentence) |
| :--- | :--- | :--- |
| 1 | **It is the only... that I know that...**<br>(强调独特性/排他性) | "It is the only system that I know that has every single line of code, the chip, the system, every line of code safety certified." |
| 2 | **Whether it's A or B, we're going to...**<br>(论证普适性/全覆盖) | "So whether it's an EDA or SDA... we're going to have basically the same technology... now completely revolutionize these design stacks." |
| 3 | **It stands to reason that...**<br>(逻辑推论/理所当然) | "It stands to reason that when AI starts to get deployed in the world's enterprises, it's going to also reinvent the way storage is done." |
| 4 | **...is an inflection point for...**<br>(描述重大转折点/机遇) | "And not to mention, as I mentioned, o1's introduction was an inflection point for AI." |
| 5 | **Long before you have to...**<br>(强调领先性/提前规划) | "You're going to be tested and evaluated in a computer long before long before you have to spend any time dealing with gravity." |

---

## 二、 高级核心词汇 (Vocabulary)

### 1. 工程与系统类

* **Redundant / Redundancy** [B2] (冗余)
> "The entire model system is based on a sensors are diverse and **redundant** and so is the self-driving car stack."


* **Traceable** [C1] (可追溯的)
> "That entire AV stack is built to be fully **traceable** and it's taken us some five years to build."


* **Vertically Integrated** [C1] (垂直整合)
> "This entire stack is **vertically integrated**. Of course, in the case of Mercedes-Benz, we built the entire stack together."


* **Micron precision** [C1] (微米级精度)
> "High-speed robots place components with **micron precision** before the Vera CPU and two Reuben GPUs complete the assembly."


* **Coherent** [B2] (一致的/连贯的)
> "Vera and Reuben are co-designed from the start to bidirectionally and **coherently** share data faster."


* **Offload** [C1] (卸载/分流)
> "Bluefield 4 DPU **offloads** storage and security so compute stays fully focused on AI."



### 2. 商业战略类

* **Indispensable** [C1] (不可或缺的)
> "Synopsis and Cadence are completely completely **indispensable** in the world of chip design."


* **Sophistication** [C1] (复杂性/成熟度)
> "...the technology that we're creating is at a level of **sophistication** and capability that we can now help them."


* **Skyrocketing** [B2] (飞速增长)
> "The amount of computation necessary for AI is **skyrocketing**. The demand for NVIDIA GPUs is **skyrocketing**."


* **Pricing power** [C1] (定价权)
> "This is your time to market. This is technology leadership. This is your **pricing power**."



---

## 三、 高级短语与术语 (Phrases & Terminology)

### 1. 技术场景短语

* **State-of-the-art** (最先进的)
> "...we decided that we have to advance the **state-of-the-art** of computation every single year."


* **Address a fundamental challenge** (解决根本挑战)
> "Vera Rubin is designed to **address this fundamental challenge** that we have."


* **In transit / At rest** (传输中/静态存储)
> "Meaning everything is encoded **in transit at rest** and during compute..."


* **Overprovision** (过度配置/预留过多)
> "...so that you don't have to **overprovision** by 25 times... you don't have to leave 25% of the energy squandered."


* **Inflection point** (转折点)
> "...and this **inflection point** of going from not autonomous vehicles to autonomous vehicles is probably happening right about this time."



### 2. 描述性能提升

* **Factor of 10x / Order of magnitude** (十倍/数量级)
> "...because models are increasing by a **factor of 10**, an **order of magnitude** every single year."


* **By far the largest** (迄今为止最大的)
> "...my guess is that... open-source models will be **by far the largest**."


* **Step up in performance** (性能的跨越/提升)
> "This is how we were able to deliver such a gigantic **step up in performance**..."



---

### 💡 学习建议：如何内化这些句子？

你可以尝试**“场景替换法”**。

* **原句：** "It is the only system that I know that has every single line of code safety certified."
* **模仿：** "It is the only **solution** that I know that **can reduce the cost by 50% without losing quality**." (这是我所知道的唯一一个既能降低50%成本又不损失质量的方案。)

**如果你需要我针对某个特定行业（比如医疗、金融、纯软件开发）将这些句式做“二次改写”练习，欢迎随时告诉我！**
